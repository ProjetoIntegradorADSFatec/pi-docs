{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Projeto Integrador ADS Fatec \u00b6 Projeto Integrador ADS Fatec - S\u00e3o Jos\u00e9 dos Campos proposto pela empresa Visiona para a identifica\u00e7\u00e3o de talh\u00f5es (unidade m\u00ednima de cultivo de uma propriedade com caracter\u00edsticas em comum). Projeto Oficial Github ; Sprints e Evolu\u00e7\u00e3o do C\u00f3digo Fonte do Projeto ; Componentes \u00b6 Sistema Inteligente - constru\u00e7\u00e3o da base de dados a ser consumida; API Restful - interm\u00e9dio para a base de dados e o sistema Web GIS; Sistema Web GIS - visualiza\u00e7\u00e3o do resultado final; Solu\u00e7\u00e3o \u00b6 Desenvolver um Sistema inteligente para a identifica\u00e7\u00e3o autom\u00e1tica de Talh\u00f5es com uso de Intelig\u00eancia Artificial e processos de classifica\u00e7\u00e3o de imagens e com um projeto Web Gis - Sistema de informa\u00e7\u00e3o Geogr\u00e1fico - contendo uma interface gr\u00e1fica agrad\u00e1vel ao usu\u00e1rio e de f\u00e1cil utiliza\u00e7\u00e3o e intuitiva, com uma \u00e1rea de visualiza\u00e7\u00e3o de imagens do mapa, conforme a regi\u00e3o e o per\u00edodo de tempo selecionados pelo usu\u00e1rio, permitindo a manipula\u00e7\u00e3o da imagem (aumentar ou diminuir e demarca\u00e7\u00e3o) e permitir o download desse arquivo para armazenamento. Integrantes do Grupo \u00b6 T\u00e1bata Gl\u00f3ria (Scrum Master - SM) Abner Ern\u00e2ni dos Anjos (Product Owner - PO) Jo\u00e3o de Freitas (Developer - DEV) Jo\u00e3o Arruda (Front end Developer - DEV) Guilherme Gomes (Back end Developer - DEV) Implementa\u00e7\u00e3o \u00b6 Como implementar? Tecnologias. Plataformas. Ferramentas. Para a implementa\u00e7\u00e3o ser\u00e1 necess\u00e1rio a utiliza\u00e7\u00e3o das seguintes tecnologias: Landsat-8 API: sat\u00e9lite de observa\u00e7\u00e3o da Terra, esses dados das imagens podem ser usados facilmente com qualquer software que reconhe\u00e7a arquivos GeoTIFF atrav\u00e9s de um arquivo CSV de \u00edndice dos dados do Landsat. Sentinel-2 API: constela\u00e7\u00e3o de dois sat\u00e9lites de observa\u00e7\u00e3o da Terra SEUS Os dados s\u00e3o ideais para aplicativos de agricultura, silvicultura e outros tipos de administra\u00e7\u00e3o de terra. esse conjunto de dados est\u00e1 dispon\u00edvel gratuitamente no programa Google Public Cloud Data. Geo Server: servidor de c\u00f3digo aberto escrito em Java que permite aos usu\u00e1rios compartilhar, processar e editar dados geoespaciais. Projetado para interoperabilidade, publica dados de qualquer fonte de dados espaciais importantes usando padr\u00f5es abertos. PostgreSQL: sistema de gerenciamento de banco de dados objeto-relacional (SGBDOR) baseado no POSTGRES Vers\u00e3o 4.2. Spring Boot: facilitar o processo de configura\u00e7\u00e3o e publica\u00e7\u00e3o de aplica\u00e7\u00f5es. Pode-se escolher os m\u00f3dulos que precisa atrav\u00e9s dos starters que inclui no pom.xml do projeto. Basicamente, s\u00e3o depend\u00eancias que agrupam outras depend\u00eancias. Angular: estrutura de design de aplicativo e plataforma de desenvolvimento para criar aplicativos de p\u00e1gina \u00fanica eficientes e sofisticados. Java: linguagem de programa\u00e7\u00e3o orientada a objetos que \u00e9 amplamente usada para o desenvolvimento de sites e aplicativos. Permite o desenvolvimento de programas multiplataforma, que podem ser executados em qualquer dispositivo. Python: linguagem de programa\u00e7\u00e3o de alto n\u00edvel, interpretada, de script, imperativa, orientada a objetos, funcional, de tipagem din\u00e2mica e forte, para a implementa\u00e7\u00e3o da inteligencia artificial. Conda Environment: gerenciador de ambientes virtuais para a linguagem python. Mkdocs: gerador de documenta\u00e7\u00e3o baseado na linguagem python. Github: Sistema de controle de vers\u00e3o distribuido e gerenciamento de c\u00f3digo-fonte, fornece controle de acesso e v\u00e1rios recursos de colabora\u00e7\u00e3o, como rastreamento de erros, solicita\u00e7\u00f5es de recursos, gerenciamento de tarefas e wikis para cada projeto. Microsoft TEAM: Trata-se de um aplicativo de bate-papo em grupo que permite o gerenciamento de diversas conversas em um \u00fanico ambiente de controle. Foi desenvolvido para facilitar a comunica\u00e7\u00e3o e promover a colabora\u00e7\u00e3o entre as equipes da empresa/projeto. Contato para D\u00favidas \u00b6 abner.anjos@fatec.sp.gov.br (Abner Ern\u00e2ni dos Anjos) joao.freitas15@fatec.sp.gov.br (Jo\u00e3o de Freitas)","title":"Home"},{"location":"#projeto-integrador-ads-fatec","text":"Projeto Integrador ADS Fatec - S\u00e3o Jos\u00e9 dos Campos proposto pela empresa Visiona para a identifica\u00e7\u00e3o de talh\u00f5es (unidade m\u00ednima de cultivo de uma propriedade com caracter\u00edsticas em comum). Projeto Oficial Github ; Sprints e Evolu\u00e7\u00e3o do C\u00f3digo Fonte do Projeto ;","title":"Projeto Integrador ADS Fatec"},{"location":"#componentes","text":"Sistema Inteligente - constru\u00e7\u00e3o da base de dados a ser consumida; API Restful - interm\u00e9dio para a base de dados e o sistema Web GIS; Sistema Web GIS - visualiza\u00e7\u00e3o do resultado final;","title":"Componentes"},{"location":"#solucao","text":"Desenvolver um Sistema inteligente para a identifica\u00e7\u00e3o autom\u00e1tica de Talh\u00f5es com uso de Intelig\u00eancia Artificial e processos de classifica\u00e7\u00e3o de imagens e com um projeto Web Gis - Sistema de informa\u00e7\u00e3o Geogr\u00e1fico - contendo uma interface gr\u00e1fica agrad\u00e1vel ao usu\u00e1rio e de f\u00e1cil utiliza\u00e7\u00e3o e intuitiva, com uma \u00e1rea de visualiza\u00e7\u00e3o de imagens do mapa, conforme a regi\u00e3o e o per\u00edodo de tempo selecionados pelo usu\u00e1rio, permitindo a manipula\u00e7\u00e3o da imagem (aumentar ou diminuir e demarca\u00e7\u00e3o) e permitir o download desse arquivo para armazenamento.","title":"Solu\u00e7\u00e3o"},{"location":"#integrantes-do-grupo","text":"T\u00e1bata Gl\u00f3ria (Scrum Master - SM) Abner Ern\u00e2ni dos Anjos (Product Owner - PO) Jo\u00e3o de Freitas (Developer - DEV) Jo\u00e3o Arruda (Front end Developer - DEV) Guilherme Gomes (Back end Developer - DEV)","title":"Integrantes do Grupo"},{"location":"#implementacao","text":"Como implementar? Tecnologias. Plataformas. Ferramentas. Para a implementa\u00e7\u00e3o ser\u00e1 necess\u00e1rio a utiliza\u00e7\u00e3o das seguintes tecnologias: Landsat-8 API: sat\u00e9lite de observa\u00e7\u00e3o da Terra, esses dados das imagens podem ser usados facilmente com qualquer software que reconhe\u00e7a arquivos GeoTIFF atrav\u00e9s de um arquivo CSV de \u00edndice dos dados do Landsat. Sentinel-2 API: constela\u00e7\u00e3o de dois sat\u00e9lites de observa\u00e7\u00e3o da Terra SEUS Os dados s\u00e3o ideais para aplicativos de agricultura, silvicultura e outros tipos de administra\u00e7\u00e3o de terra. esse conjunto de dados est\u00e1 dispon\u00edvel gratuitamente no programa Google Public Cloud Data. Geo Server: servidor de c\u00f3digo aberto escrito em Java que permite aos usu\u00e1rios compartilhar, processar e editar dados geoespaciais. Projetado para interoperabilidade, publica dados de qualquer fonte de dados espaciais importantes usando padr\u00f5es abertos. PostgreSQL: sistema de gerenciamento de banco de dados objeto-relacional (SGBDOR) baseado no POSTGRES Vers\u00e3o 4.2. Spring Boot: facilitar o processo de configura\u00e7\u00e3o e publica\u00e7\u00e3o de aplica\u00e7\u00f5es. Pode-se escolher os m\u00f3dulos que precisa atrav\u00e9s dos starters que inclui no pom.xml do projeto. Basicamente, s\u00e3o depend\u00eancias que agrupam outras depend\u00eancias. Angular: estrutura de design de aplicativo e plataforma de desenvolvimento para criar aplicativos de p\u00e1gina \u00fanica eficientes e sofisticados. Java: linguagem de programa\u00e7\u00e3o orientada a objetos que \u00e9 amplamente usada para o desenvolvimento de sites e aplicativos. Permite o desenvolvimento de programas multiplataforma, que podem ser executados em qualquer dispositivo. Python: linguagem de programa\u00e7\u00e3o de alto n\u00edvel, interpretada, de script, imperativa, orientada a objetos, funcional, de tipagem din\u00e2mica e forte, para a implementa\u00e7\u00e3o da inteligencia artificial. Conda Environment: gerenciador de ambientes virtuais para a linguagem python. Mkdocs: gerador de documenta\u00e7\u00e3o baseado na linguagem python. Github: Sistema de controle de vers\u00e3o distribuido e gerenciamento de c\u00f3digo-fonte, fornece controle de acesso e v\u00e1rios recursos de colabora\u00e7\u00e3o, como rastreamento de erros, solicita\u00e7\u00f5es de recursos, gerenciamento de tarefas e wikis para cada projeto. Microsoft TEAM: Trata-se de um aplicativo de bate-papo em grupo que permite o gerenciamento de diversas conversas em um \u00fanico ambiente de controle. Foi desenvolvido para facilitar a comunica\u00e7\u00e3o e promover a colabora\u00e7\u00e3o entre as equipes da empresa/projeto.","title":"Implementa\u00e7\u00e3o"},{"location":"#contato-para-duvidas","text":"abner.anjos@fatec.sp.gov.br (Abner Ern\u00e2ni dos Anjos) joao.freitas15@fatec.sp.gov.br (Jo\u00e3o de Freitas)","title":"Contato para D\u00favidas"},{"location":"api-restful/","text":"API Spring Boot RESTful \u00b6 Projeto Integrador entre o sexto per\u00edodo da Faculdade de Tecnologia de S\u00e3o Jos\u00e9 dos Campos, Professor Jessen Vidal de An\u00e1lise e Desenvolvimento de Sistemas e a empresa Visiona , para qual nos forneceu o problema da identifica\u00e7\u00e3o de talh\u00f5es em imagens de sensoriamento remoto. Para o funcionamento da API Spring Boot com o cat\u00e1logo de imagens, \u00e9 necess\u00e1rio os seguintes requisitos: Uma inst\u00e2ncia do banco de dados PostgreSQL/PostGIS em execu\u00e7\u00e3o e configurado; Um servidor de mapas Geoserver em execu\u00e7\u00e3o e configurado; Projeto \u00b6 Este projeto consiste em: Desenvolvimento de uma API RESTful para o cat\u00e1logo de imagens georreferenciados em um banco de dados PostGIS; Com dados multitemporais, utilizar-se de intelig\u00eancia artificial para identificar talh\u00f5es em uma \u00e1rea de interesse. Ferramentas \u00b6 CI \u00c9 necess\u00e1rio uma m\u00e1quina virtual, esta servir\u00e1 para o software Jenkins que executar\u00e1 os processos de Integra\u00e7\u00e3o Cont\u00ednua. Se a m\u00e1quina for local, utilize o ngrok, um servi\u00e7o gratuito de tunelamento sem configura\u00e7\u00e3o de firewall ou port forwarding. Agora no Jenkins deve-se configurar a pipeline de testes nos seguintes passos: Clone : Para buscar o reposit\u00f3rio com os novos dados; Environment : Instala as depend\u00eancias do projeto; Testes : Execu\u00e7\u00e3o dos Testes JUnit. Configuar Webhook no GitHUB para o endpoint do Jenkins ( URL do ngrok se foi utilizado ) e ativar a op\u00e7\u00e3o: * GitHub hook trigger for GITScm polling CD a definir processo de deploy. Instala\u00e7\u00e3o e execu\u00e7\u00e3o da aplica\u00e7\u00e3o \u00b6 Instala\u00e7\u00e3o para o ambiente de desenvolvimento \u00b6 Obs.: Necess\u00e1rio instala\u00e7\u00e3o do gradle 5+ . $ gradle bootRun Execu\u00e7\u00e3o da aplica\u00e7\u00e3o em micro servi\u00e7os \u00b6 Obs.: N\u00e3o esque\u00e7a de mudar o endere\u00e7o IP (localhost) do banco de dados no arquivo application.properties para o endere\u00e7o real do servidor PostgreSQL do seu computador. ## Gerar o arquivo execut\u00e1vel `.jar` utilizando o Gradle 5 $ gradle build ## Construir a imagem docker com base no `Dockerfile` $ docker build -t spring-restful . ## Executar o container localmente $ docker run --name spring-api-restful -p 4040:8080 -d spring-restful O banco de dados criado por essa aplica\u00e7\u00e3o possui o seguinte modelo de rela\u00e7\u00f5es: Ap\u00f3s o comando docker run digite o seguinte docker ps para listar os servi\u00e7os em execu\u00e7\u00e3o pelo seu docker instalado, a resposta deve ser a seguinte: $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 20b1962dad83 spring-restful \"java -jar /app.jar\" 3 minutes ago Up 3 minutes 0 .0.0.0:4040->8080/tcp spring-api-restful Em seu navegador digite o seguinte link localhost:4040/catalog/list . Opera\u00e7\u00f5es \u00b6 Cadastro de usu\u00e1rios: somente o usu\u00e1rio admin pode adicionar outros usu\u00e1rios, a partir de um m\u00e9todo POST: POST localhost:4040/login Request Body { \"username\" : \"admin\" , \"password\" : \"admin\" } POST localhost:4040/users/sign-up Request Body { \"username\" : \"fulano\" , \"password\" : \"123\" } Listagem: lista todas as imagens cadastradas no banco de dados PostgreSQL por m\u00e9todo GET, onde todos os usu\u00e1rios podem acessar a lista de imagens: GET localhost:4040/catalog/list Response { \"features\" : [ { \"id\" : 1 , \"assets\" : [ { \"name\" : \"VH\" , \"href\" : \"http://www.dpi.inpe.br/obt/agricultural-database/lem/dados/cenas/Sentinel1/20180408_S1A/clip_20180408T083549_Sigma0_VH_db.tif\" } ], \"bbox\" : [ -45.8734130859375 , -12.042006714207925 , -45.7415771484375 , -12.224602049269444 ], \"collection\" : \"clip_20180408T083549_Sigma0_VH_db.tif\" , \"geometry\" : { \"type\" : \"Polygon\" , \"coordinates\" : [ [ [ -12.042006714207925 , -45.8734130859375 ], [ -12.224602049269444 , -45.7415771484375 ] ] ] }, \"properties\" : { \"projection\" : \"EPSG:4326\" , \"band\" : \"VH\" , \"datetime\" : { \"start\" : \"2018-01-08T02:04:00.000+0000\" , \"end\" : \"2018-01-08T02:04:00.000+0000\" } }, \"type\" : \"sentinel A image clip_Sigma0_VH_db.tif INPE\" } ], \"numberMatched\" : 17 , \"numberReturned\" : 19 , \"type\" : \"FeatureCollection\" } Cadastro de imagens: cadastra uma imagem com os atributos definidos nos exemplos no banco de dados PostgreSQL por m\u00e9todo POST, onde somente o usu\u00e1rio administrador pode adicionar imagens: POST localhost:4040/catalog/add Request Body { \"name\" : \"clip_20170612T083546_Sigma0_VH_db\" , \"description\" : \"sentinel A image clip_Sigma0_VH_db.tif INPE\" , \"band\" : \"VH\" , \"dateTime\" : \"2017-06-12 08:35:46\" , \"coordinates\" : [ { \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.042006714207925 , \"longitude\" : -45.8734130859375 }, { \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.224602049269444 , \"longitude\" : -45.7415771484375 } ], \"image\" : \"http://www.dpi.inpe.br/agricultural-database/lem/dados/cenas/Sentinel1/20170612_S1A/clip_20170612T083546_Sigma0_VH_db.tif\" } Busca de imagens: busca imagens a partir de uma dado pol\u00edgono formatado em GeoJSON com os atributos definidos nos exemplos em proje\u00e7\u00e3o EPSG:4326 com banco de dados PostgreSQL por m\u00e9todo POST, todos os usu\u00e1rios podem realizar pesquisas: POST localhost:4040/catalog/search Request Body { \"type\" : \"FeatureCollection\" , \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"dateTime\" : { \"start\" : \"2010-01-01\" , \"end\" : \"2017-12-31\" }, \"band\" : \"VV\" , \"projection\" : \"EPSG:4326\" }, \"geometry\" : { \"type\" : \"Polygon\" , \"coordinates\" : [[ [ -47.02148437499999 , -10.790140750321738 ], ... ]] } } ] } Obs.: Voc\u00ea pode aprender mais sobre GeoJSON's com o geojson.io . Refer\u00eancias \u00b6 Visiona ; Jenkins ; ngrok ;","title":"About"},{"location":"api-restful/#api-spring-boot-restful","text":"Projeto Integrador entre o sexto per\u00edodo da Faculdade de Tecnologia de S\u00e3o Jos\u00e9 dos Campos, Professor Jessen Vidal de An\u00e1lise e Desenvolvimento de Sistemas e a empresa Visiona , para qual nos forneceu o problema da identifica\u00e7\u00e3o de talh\u00f5es em imagens de sensoriamento remoto. Para o funcionamento da API Spring Boot com o cat\u00e1logo de imagens, \u00e9 necess\u00e1rio os seguintes requisitos: Uma inst\u00e2ncia do banco de dados PostgreSQL/PostGIS em execu\u00e7\u00e3o e configurado; Um servidor de mapas Geoserver em execu\u00e7\u00e3o e configurado;","title":"API Spring Boot RESTful"},{"location":"api-restful/#projeto","text":"Este projeto consiste em: Desenvolvimento de uma API RESTful para o cat\u00e1logo de imagens georreferenciados em um banco de dados PostGIS; Com dados multitemporais, utilizar-se de intelig\u00eancia artificial para identificar talh\u00f5es em uma \u00e1rea de interesse.","title":"Projeto"},{"location":"api-restful/#ferramentas","text":"CI \u00c9 necess\u00e1rio uma m\u00e1quina virtual, esta servir\u00e1 para o software Jenkins que executar\u00e1 os processos de Integra\u00e7\u00e3o Cont\u00ednua. Se a m\u00e1quina for local, utilize o ngrok, um servi\u00e7o gratuito de tunelamento sem configura\u00e7\u00e3o de firewall ou port forwarding. Agora no Jenkins deve-se configurar a pipeline de testes nos seguintes passos: Clone : Para buscar o reposit\u00f3rio com os novos dados; Environment : Instala as depend\u00eancias do projeto; Testes : Execu\u00e7\u00e3o dos Testes JUnit. Configuar Webhook no GitHUB para o endpoint do Jenkins ( URL do ngrok se foi utilizado ) e ativar a op\u00e7\u00e3o: * GitHub hook trigger for GITScm polling CD a definir processo de deploy.","title":"Ferramentas"},{"location":"api-restful/#instalacao-e-execucao-da-aplicacao","text":"","title":"Instala\u00e7\u00e3o e execu\u00e7\u00e3o da aplica\u00e7\u00e3o"},{"location":"api-restful/#instalacao-para-o-ambiente-de-desenvolvimento","text":"Obs.: Necess\u00e1rio instala\u00e7\u00e3o do gradle 5+ . $ gradle bootRun","title":"Instala\u00e7\u00e3o para o ambiente de desenvolvimento"},{"location":"api-restful/#execucao-da-aplicacao-em-micro-servicos","text":"Obs.: N\u00e3o esque\u00e7a de mudar o endere\u00e7o IP (localhost) do banco de dados no arquivo application.properties para o endere\u00e7o real do servidor PostgreSQL do seu computador. ## Gerar o arquivo execut\u00e1vel `.jar` utilizando o Gradle 5 $ gradle build ## Construir a imagem docker com base no `Dockerfile` $ docker build -t spring-restful . ## Executar o container localmente $ docker run --name spring-api-restful -p 4040:8080 -d spring-restful O banco de dados criado por essa aplica\u00e7\u00e3o possui o seguinte modelo de rela\u00e7\u00f5es: Ap\u00f3s o comando docker run digite o seguinte docker ps para listar os servi\u00e7os em execu\u00e7\u00e3o pelo seu docker instalado, a resposta deve ser a seguinte: $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 20b1962dad83 spring-restful \"java -jar /app.jar\" 3 minutes ago Up 3 minutes 0 .0.0.0:4040->8080/tcp spring-api-restful Em seu navegador digite o seguinte link localhost:4040/catalog/list .","title":"Execu\u00e7\u00e3o da aplica\u00e7\u00e3o em micro servi\u00e7os"},{"location":"api-restful/#operacoes","text":"Cadastro de usu\u00e1rios: somente o usu\u00e1rio admin pode adicionar outros usu\u00e1rios, a partir de um m\u00e9todo POST: POST localhost:4040/login Request Body { \"username\" : \"admin\" , \"password\" : \"admin\" } POST localhost:4040/users/sign-up Request Body { \"username\" : \"fulano\" , \"password\" : \"123\" } Listagem: lista todas as imagens cadastradas no banco de dados PostgreSQL por m\u00e9todo GET, onde todos os usu\u00e1rios podem acessar a lista de imagens: GET localhost:4040/catalog/list Response { \"features\" : [ { \"id\" : 1 , \"assets\" : [ { \"name\" : \"VH\" , \"href\" : \"http://www.dpi.inpe.br/obt/agricultural-database/lem/dados/cenas/Sentinel1/20180408_S1A/clip_20180408T083549_Sigma0_VH_db.tif\" } ], \"bbox\" : [ -45.8734130859375 , -12.042006714207925 , -45.7415771484375 , -12.224602049269444 ], \"collection\" : \"clip_20180408T083549_Sigma0_VH_db.tif\" , \"geometry\" : { \"type\" : \"Polygon\" , \"coordinates\" : [ [ [ -12.042006714207925 , -45.8734130859375 ], [ -12.224602049269444 , -45.7415771484375 ] ] ] }, \"properties\" : { \"projection\" : \"EPSG:4326\" , \"band\" : \"VH\" , \"datetime\" : { \"start\" : \"2018-01-08T02:04:00.000+0000\" , \"end\" : \"2018-01-08T02:04:00.000+0000\" } }, \"type\" : \"sentinel A image clip_Sigma0_VH_db.tif INPE\" } ], \"numberMatched\" : 17 , \"numberReturned\" : 19 , \"type\" : \"FeatureCollection\" } Cadastro de imagens: cadastra uma imagem com os atributos definidos nos exemplos no banco de dados PostgreSQL por m\u00e9todo POST, onde somente o usu\u00e1rio administrador pode adicionar imagens: POST localhost:4040/catalog/add Request Body { \"name\" : \"clip_20170612T083546_Sigma0_VH_db\" , \"description\" : \"sentinel A image clip_Sigma0_VH_db.tif INPE\" , \"band\" : \"VH\" , \"dateTime\" : \"2017-06-12 08:35:46\" , \"coordinates\" : [ { \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.042006714207925 , \"longitude\" : -45.8734130859375 }, { \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.224602049269444 , \"longitude\" : -45.7415771484375 } ], \"image\" : \"http://www.dpi.inpe.br/agricultural-database/lem/dados/cenas/Sentinel1/20170612_S1A/clip_20170612T083546_Sigma0_VH_db.tif\" } Busca de imagens: busca imagens a partir de uma dado pol\u00edgono formatado em GeoJSON com os atributos definidos nos exemplos em proje\u00e7\u00e3o EPSG:4326 com banco de dados PostgreSQL por m\u00e9todo POST, todos os usu\u00e1rios podem realizar pesquisas: POST localhost:4040/catalog/search Request Body { \"type\" : \"FeatureCollection\" , \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"dateTime\" : { \"start\" : \"2010-01-01\" , \"end\" : \"2017-12-31\" }, \"band\" : \"VV\" , \"projection\" : \"EPSG:4326\" }, \"geometry\" : { \"type\" : \"Polygon\" , \"coordinates\" : [[ [ -47.02148437499999 , -10.790140750321738 ], ... ]] } } ] } Obs.: Voc\u00ea pode aprender mais sobre GeoJSON's com o geojson.io .","title":"Opera\u00e7\u00f5es"},{"location":"api-restful/#referencias","text":"Visiona ; Jenkins ; ngrok ;","title":"Refer\u00eancias"},{"location":"api-restful/db/","text":"API Spring Boot PostgreSQL \u00b6 Scripts em PSQL para criar as tabelas de fei\u00e7\u00f5es para as buscas de \u00e1reas de interesse para o Sistema Web de visualiza\u00e7\u00e3o com migra\u00e7\u00e3o de dados para um banco PostgreSQL e executar em um container docker. Assim como a configura\u00e7\u00e3o do ambiente de desenvolvimento utilizando o gerenciador de container Docker com amplo uso da extens\u00e3o Postgis para o processamento de opera\u00e7\u00f5es geogr\u00e1ficas. Cria\u00e7\u00e3o do container docker PostgreSQL \u00b6 ## Download do reposit\u00f3rio oficial $ docker pull mdillon/postgis ## Execu\u00e7\u00e3o do container com uma inst\u00e2ncia do Postgresql $ docker run --name postgresql -p 5480:5432 -e POSTGRES_PASSWORD=postgres -d mdillon/postgis Container docker database \u00b6 Cria\u00e7\u00e3o do container docker PGAdmin4 (Interface Gr\u00e1fica) ## Download do reposit\u00f3rio oficial $ docker pull dpage/pgadmin4 ## Execu\u00e7\u00e3o do container com uma inst\u00e2ncia do PGAdmin $ docker run --name pgadmin4 -p 16543:80 -e PGADMIN_DEFAULT_EMAIL,PGADMIN_DEFAULT_PASSWORD=abner.anjos@fatec.sp.gov.br,postgres -d dpage/pgadmin4 Cria\u00e7\u00e3o do container docker PostgreSQL e PGAdmin4 (Interface Gr\u00e1fica) por default com o Docker Compose $ docker-compose up -d postgresql pgadmin4 Obs.: Ser\u00e1 necess\u00e1rio instalar a ferramenta (docker-compose)[https://docs.docker.com/compose/] e n\u00e3o esque\u00e7a de cadastrar o servidor de banco de dados PostgreSQL para o uso da interface gr\u00e1fica PGAdmin4 com as credenciais necess\u00e1rias Ambiente PSQL \u00b6 ## Instala\u00e7\u00e3o do ambiente psql CLI interface da linha de comando $ sudo apt install postgresql Migra\u00e7\u00e3o dos dados \u00b6 ## Cria\u00e7\u00e3o do banco de dados para a migra\u00e7\u00e3o $ createdb -h 0.0.0.0 -p 5480 -U postgres shapes \"Camada de fei\u00e7\u00f5es para a defini\u00e7\u00e3o de talh\u00f5es\" ## Alterando as permiss\u00f5es (exemplo) $ sudo chmod 777 -R ../db ## Cria\u00e7\u00e3o do usuario Postgres para a API e migra\u00e7\u00e3o dos dados em csv $ psql -h 0.0.0.0 -p 5480 -U postgres -d shapes -f create-tables.sql O banco de dados de cat\u00e1logo de imagens criado por essa aplica\u00e7\u00e3o possui o seguinte modelo de rela\u00e7\u00f5es: Gerenciamento do Banco de dados \u00b6 ## Entrar no banco de dados digitar a senha cadastrada para entrar $ psql -h 0.0.0.0 -p 5480 -U api_restful -d shapes ## Verificar se as tabelas e a extens\u00e3o foram criadas shapes=> SELECT table_name FROM information_schema.tables WHERE table_schema='public'; table_name ------------------- raster_columns raster_overviews municipios geography_columns geometry_columns spatial_ref_sys (6 rows) Ap\u00f3s a instala\u00e7\u00e3o do ambiente de desenvolvimento em seu navegador acesse o pgAdmin4 com o endere\u00e7o 16543 . Obs.: Colocar as credenciais do arquivo docker-compose.yml configuradas acima.","title":"Data Base"},{"location":"api-restful/db/#api-spring-boot-postgresql","text":"Scripts em PSQL para criar as tabelas de fei\u00e7\u00f5es para as buscas de \u00e1reas de interesse para o Sistema Web de visualiza\u00e7\u00e3o com migra\u00e7\u00e3o de dados para um banco PostgreSQL e executar em um container docker. Assim como a configura\u00e7\u00e3o do ambiente de desenvolvimento utilizando o gerenciador de container Docker com amplo uso da extens\u00e3o Postgis para o processamento de opera\u00e7\u00f5es geogr\u00e1ficas.","title":"API Spring Boot PostgreSQL"},{"location":"api-restful/db/#criacao-do-container-docker-postgresql","text":"## Download do reposit\u00f3rio oficial $ docker pull mdillon/postgis ## Execu\u00e7\u00e3o do container com uma inst\u00e2ncia do Postgresql $ docker run --name postgresql -p 5480:5432 -e POSTGRES_PASSWORD=postgres -d mdillon/postgis","title":"Cria\u00e7\u00e3o do container docker PostgreSQL"},{"location":"api-restful/db/#container-docker-database","text":"Cria\u00e7\u00e3o do container docker PGAdmin4 (Interface Gr\u00e1fica) ## Download do reposit\u00f3rio oficial $ docker pull dpage/pgadmin4 ## Execu\u00e7\u00e3o do container com uma inst\u00e2ncia do PGAdmin $ docker run --name pgadmin4 -p 16543:80 -e PGADMIN_DEFAULT_EMAIL,PGADMIN_DEFAULT_PASSWORD=abner.anjos@fatec.sp.gov.br,postgres -d dpage/pgadmin4 Cria\u00e7\u00e3o do container docker PostgreSQL e PGAdmin4 (Interface Gr\u00e1fica) por default com o Docker Compose $ docker-compose up -d postgresql pgadmin4 Obs.: Ser\u00e1 necess\u00e1rio instalar a ferramenta (docker-compose)[https://docs.docker.com/compose/] e n\u00e3o esque\u00e7a de cadastrar o servidor de banco de dados PostgreSQL para o uso da interface gr\u00e1fica PGAdmin4 com as credenciais necess\u00e1rias","title":"Container docker database"},{"location":"api-restful/db/#ambiente-psql","text":"## Instala\u00e7\u00e3o do ambiente psql CLI interface da linha de comando $ sudo apt install postgresql","title":"Ambiente PSQL"},{"location":"api-restful/db/#migracao-dos-dados","text":"## Cria\u00e7\u00e3o do banco de dados para a migra\u00e7\u00e3o $ createdb -h 0.0.0.0 -p 5480 -U postgres shapes \"Camada de fei\u00e7\u00f5es para a defini\u00e7\u00e3o de talh\u00f5es\" ## Alterando as permiss\u00f5es (exemplo) $ sudo chmod 777 -R ../db ## Cria\u00e7\u00e3o do usuario Postgres para a API e migra\u00e7\u00e3o dos dados em csv $ psql -h 0.0.0.0 -p 5480 -U postgres -d shapes -f create-tables.sql O banco de dados de cat\u00e1logo de imagens criado por essa aplica\u00e7\u00e3o possui o seguinte modelo de rela\u00e7\u00f5es:","title":"Migra\u00e7\u00e3o dos dados"},{"location":"api-restful/db/#gerenciamento-do-banco-de-dados","text":"## Entrar no banco de dados digitar a senha cadastrada para entrar $ psql -h 0.0.0.0 -p 5480 -U api_restful -d shapes ## Verificar se as tabelas e a extens\u00e3o foram criadas shapes=> SELECT table_name FROM information_schema.tables WHERE table_schema='public'; table_name ------------------- raster_columns raster_overviews municipios geography_columns geometry_columns spatial_ref_sys (6 rows) Ap\u00f3s a instala\u00e7\u00e3o do ambiente de desenvolvimento em seu navegador acesse o pgAdmin4 com o endere\u00e7o 16543 . Obs.: Colocar as credenciais do arquivo docker-compose.yml configuradas acima.","title":"Gerenciamento do Banco de dados"},{"location":"api-restful/geoserver/","text":"Configura\u00e7\u00e3o inicial do Servidor de mapas Geoserver \u00b6 Configura\u00e7\u00e3o inicial do servidor de mapas geoserver para a postagem de camadas a serem consumidas pelo Sistema Web de visualiza\u00e7\u00e3o e identifica\u00e7\u00e3o de Talh\u00f5es proposto pelo projeto integrador Aqui neste arquivo a prioridade e a estrutura de microsservi\u00e7os, portanto vamos priorizar a instala\u00e7\u00e3o por meio da ferramenta de gerenciamento de container Docker. Montagem do ambiente de desenvolvimento \u00b6 ## Download da imagem $ docker pull kartoza/geoserver ## execu\u00e7\u00e3o do container Docker $ docker run -d -p 8686:8080 --name geoserver -e STABLE_EXTENSIONS=charts-plugin,db2-plugin kartoza/geoserver Postagem das camadas \u00b6 Verificar se o sistema encontra em execu\u00e7\u00e3o no endere\u00e7o localhost:8686/geoserver e a p\u00e1gina de administra\u00e7\u00e3o do geoserver dever\u00e1 ser exibida. A credencial padr\u00e3o do GeoServer \u00e9 a seguinte: Usu\u00e1rio: admin Senha: geoserver Camadas necess\u00e1rias para a execu\u00e7\u00e3o: Postagem de camadas em Geotiff : postagem das camadas das imagens de sensoriamento remoto do servidor FTP do INPE com os sat\u00e9lites Landsat e Sentinel-1; Postagem de Geometrias : postagem das geometrias relacionadas a defini\u00e7\u00e3o de talh\u00f5es como resultado do sistema inteligente PythonCNN .","title":"Geoserver"},{"location":"api-restful/geoserver/#configuracao-inicial-do-servidor-de-mapas-geoserver","text":"Configura\u00e7\u00e3o inicial do servidor de mapas geoserver para a postagem de camadas a serem consumidas pelo Sistema Web de visualiza\u00e7\u00e3o e identifica\u00e7\u00e3o de Talh\u00f5es proposto pelo projeto integrador Aqui neste arquivo a prioridade e a estrutura de microsservi\u00e7os, portanto vamos priorizar a instala\u00e7\u00e3o por meio da ferramenta de gerenciamento de container Docker.","title":"Configura\u00e7\u00e3o inicial do Servidor de mapas Geoserver"},{"location":"api-restful/geoserver/#montagem-do-ambiente-de-desenvolvimento","text":"## Download da imagem $ docker pull kartoza/geoserver ## execu\u00e7\u00e3o do container Docker $ docker run -d -p 8686:8080 --name geoserver -e STABLE_EXTENSIONS=charts-plugin,db2-plugin kartoza/geoserver","title":"Montagem do ambiente de desenvolvimento"},{"location":"api-restful/geoserver/#postagem-das-camadas","text":"Verificar se o sistema encontra em execu\u00e7\u00e3o no endere\u00e7o localhost:8686/geoserver e a p\u00e1gina de administra\u00e7\u00e3o do geoserver dever\u00e1 ser exibida. A credencial padr\u00e3o do GeoServer \u00e9 a seguinte: Usu\u00e1rio: admin Senha: geoserver Camadas necess\u00e1rias para a execu\u00e7\u00e3o: Postagem de camadas em Geotiff : postagem das camadas das imagens de sensoriamento remoto do servidor FTP do INPE com os sat\u00e9lites Landsat e Sentinel-1; Postagem de Geometrias : postagem das geometrias relacionadas a defini\u00e7\u00e3o de talh\u00f5es como resultado do sistema inteligente PythonCNN .","title":"Postagem das camadas"},{"location":"changes/","text":"Sprint 1 (2020 - 03 - 20) \u00b6 Objetivo: Entregar o ambiente de desenvolvimento para o sistema completo. Valor: Estudo das poss\u00edveis plataformas de desenvolvimento e valida\u00e7\u00e3o de qual a mais adequada. Descri\u00e7\u00e3o: Nesta sprint a prioriza\u00e7\u00e3o foi a defini\u00e7\u00e3o da base de dados para a constru\u00e7\u00e3o da API Restful focando no cat\u00e1logo de imagem e no armazenamento, al\u00e9m da defini\u00e7\u00e3o da interface de usu\u00e1rio para o sistema de visualiza\u00e7\u00e3o Web GIS focando no map tile engine e no recorte e download das imagens. Atividades realizadas: Entrega da defini\u00e7\u00e3o da base de dados a ser utilizada pelo sistema inteligente como cat\u00e1logo de imagens; Adapta\u00e7\u00e3o do Sistema de visualiza\u00e7\u00e3o Web GIS com a configura\u00e7\u00e3o necess\u00e1ria para a visualiza\u00e7\u00e3o dos dados geogr\u00e1ficos; Implementa\u00e7\u00e3o do Open Layers e a estrutura\u00e7\u00e3o do template. Links para as milestones e issues relacionadas \u00e0 primeira entrega (Sprint 1): API Resful - entreg\u00e1vel para a primeira sprint relacionado a API Restful, um interm\u00e9dio para a base de dados constru\u00edda e o sistema Web GIS; Sistema Web GIS - entreg\u00e1vel para a primeira sprint relacionado ao Sistema Web GIS para visualiza\u00e7\u00e3o dos dados de teste; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o de Projetos Termo de Abertura de Projeto Gest\u00e3o de Projetos Diagrama de Tempo e Custo Gest\u00e3o de Projetos Declara\u00e7\u00e3o de escopo Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o Design Thinking Empreendedorismo Canvas Sprint 2 (2020 - 05 - 15) \u00b6 Objetivo: Montagem do ambiente de desenvolvimento do Sistema Inteligente. Valor: Estudo das poss\u00edveis metodologias para o processamento das imagens. Descri\u00e7\u00e3o: Para esta sprint propomos o desenvolvimento da configura\u00e7\u00e3o inicial do sistema inteligente para a identifica\u00e7\u00e3o de propriedades nas imagens de cobertura de terra capturadas pelo sat\u00e9lite Sentinel e Landsat priorizando a defini\u00e7\u00e3o de m\u00e1scaras. Atividades Realizadas: Entrega da primeira vers\u00e3o do sistema inteligente com a avalia\u00e7\u00e3o dos dados e primeiro processamento de imagens com o cat\u00e1logo de imagens do Sentinel-1; Habilita\u00e7\u00e3o do recorte de pol\u00edgonos no Sistema de visualiza\u00e7\u00e3o; Estrutura\u00e7\u00e3o do projeto completo em micro servi\u00e7os; Documenta\u00e7\u00e3o da instala\u00e7\u00e3o das demais depend\u00eancias como banco de dados PostgreSQL e servidor de mapas Geoserver, criando servi\u00e7os em Docker de forma a facilitar o desenvolvimento. Links para as milestones e issues relacionadas \u00e0 segunda entrega (Sprint 2): Sistema Inteligente - constru\u00e7\u00e3o da base de dados a ser consumida; API Resful - interm\u00e9dio para a base de dados e o sistema Web GIS; Sistema Web GIS - visualiza\u00e7\u00e3o do resultado final; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o BSC - Balanced Scorecard Gest\u00e3o de Projetos Diagrama de Tempo e Custo MS Project Gest\u00e3o de Projetos Vis\u00e3o Geral do Custo de Recursos Gest\u00e3o de Equipes Gr\u00e1fico de Burndown Sprint 3 (2020 - 05 - 29) \u00b6 Objetivo: Integrar as funcionalidades essenciais da busca por imagens. Valor: Funcionalidade de busca com pol\u00edgonos em GeoJSON. Descri\u00e7\u00e3o: Na sprint 3 com a base de dados definida foi efetuado alguns testes com os modelos do TensorFlow usando um misto de imagens do Sentinel e Landsat para enriquecer os dados de treinamento e valida\u00e7\u00e3o da IA, tamb\u00e9m foi desenvolvida na API Restful uma busca com pol\u00edgonos no banco de dados geogr\u00e1fico e a integra\u00e7\u00e3o com o Web GIS utilizando dados em mock. Atividades Realizadas: Cria\u00e7\u00e3o da base de dados para os os testes envolvendo o modelo criado com o TensorFlow classificador de imagens usando imagens do Sentinel e Landsat; Entrega da API Restful com a busca com pol\u00edgonos formatados em geojson verificando o recorte de imagens feito pelo Sistema Web GIS, verificando se naquele pol\u00edgono existe alguma imagem cadastrada no banco de dados geogr\u00e1fico; Entrega do controle de download do sistema Web GIS para as imagens cadastradas no banco de dados PostGIS, assim como a integra\u00e7\u00e3o com a API Restful e a implementa\u00e7\u00e3o da visualiza\u00e7\u00e3o de camadas no servidor de mapas Geoserver; Links para as milestones e issues relacionadas \u00e0 terceira entrega (Sprint 3): Sistema Inteligente - constru\u00e7\u00e3o do modelo inicial para os testes com uma base de dados m\u00ednima; API Resful - implementando buscas com GeoJSON's para uma API otimizada; Sistema Web GIS - implementando o controle de download para as imagens e a visualiza\u00e7\u00e3o de camadas com o servidor de mapas Geoserver; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o BSC - Balanced Scorecard Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o Planejamento Estrat\u00e9gico em TI Gest\u00e3o de Projetos Matriz RACI Gest\u00e3o de Projetos Checklist Gest\u00e3o de Equipes Gr\u00e1fico de Burndown Sprint 4 (2020 - 06 - 14) \u00b6 Objetivo: Implementar a pesquisa por dados espa\u00e7o-temporais. Valor: O sistema agora \u00e9 capaz de realizar buscas por imagens com atributos de espa\u00e7o (pol\u00edgonos) e tempo (intervalos de datas). Descri\u00e7\u00e3o: Entrega da API Restful funcionando com dados espa\u00e7o temporais. Para esta sprint foi proposto a cria\u00e7\u00e3o e o treinamento do modelo para a identifica\u00e7\u00e3o de talh\u00f5es assim como a defini\u00e7\u00e3o das m\u00e1scaras para as imagens, a integra\u00e7\u00e3o da API Restful com o sistema de visualiza\u00e7\u00e3o Web GIS para o download e recorte das imagens sem mock, al\u00e9m da implementa\u00e7\u00e3o de tags para os reposit\u00f3rios com controle de vers\u00f5es. Atividades Realizados: Implementa\u00e7\u00e3o do sistema de tags no reposit\u00f3rio do Github, da fun\u00e7\u00e3o de busca por dados espa\u00e7o temporais e enriquecendo a base de dados com mais imagens do Sentinel-1 como teste para o ambiente de produ\u00e7\u00e3o da API; Implementando a busca por dados espa\u00e7o-temporais no Sistema Web GIS com a integra\u00e7\u00e3o com a API utilizando um menu para a abstra\u00e7\u00e3o, habilitando o recorte por pol\u00edgonos e sele\u00e7\u00e3o de intervalos de datas; Visualiza\u00e7\u00e3o dos dados de aprendizagem na \u00e1rea de intelig\u00eancia artificial (acur\u00e1cia) do classificador e testes com o enriquecimento da base de dados da API; Links para as milestones e issues relacionadas \u00e0 quarta entrega (Sprint 4): Sistema Inteligente - visualiza\u00e7\u00e3o de aprendizagem/treino do classificador, aplica\u00e7\u00e3o de t\u00e9cnicas de aumento de dados data augmentation a base de arquivos de teste, enriquecimento da base de dados; API Resful - implementando buscas com intervalos de datas e GeoJSON's, busca por dados espa\u00e7o temporais; Sistema Web GIS - integra\u00e7\u00e3o com a API, implementa\u00e7\u00e3o da busca por dados espa\u00e7o temporais e cria\u00e7\u00e3o do menu para a filtragem das imagens; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o de Projetos ATA - Reuni\u00e3o PI ADS Gest\u00e3o de Projetos Termo de Abertura de Projeto Gest\u00e3o de Projetos Matriz RACI Gest\u00e3o de Projetos Declara\u00e7\u00e3o de Escopo Gest\u00e3o de Projetos Diagrama de Tempo e Custo Gest\u00e3o de Projetos Vis\u00e3o Geral do Custo de Recursos Gest\u00e3o de Projetos Matriz das Comunica\u00e7\u00f5es Gest\u00e3o de Equipes Gr\u00e1fico de Burndown Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o Portf\u00f3lio de Servi\u00e7o ITIL Sprint 5 (2020 - 06 - 27) \u00b6 Objetivo: Revisar o cat\u00e1logo de imagens com a especifica\u00e7\u00e3o Spatial Temporal Asset Catalog (STAC) . Valor: Cat\u00e1logo de imagens com atributos espa\u00e7o-temporais e a descri\u00e7\u00e3o de cada imagem da base de dados. Descri\u00e7\u00e3o: Entrega da Primeira vers\u00e3o do Cat\u00e1logo de Imagens . Conforme o planejamento desta sprint a prioridade \u00e9 o enriquecimento do cat\u00e1logo de imagens, assim como a base de dados do sistema inteligente e t\u00e9rmino da primeira vers\u00e3o do Web GIS com a integra\u00e7\u00e3o da API Restful. Est\u00e1 no planejamento a reformula\u00e7\u00e3o da API para os par\u00e2metros utilizados pelo Spatial Temporal Asset Catalog (STAC). Atividades Realizadas: Nesta Sprint foi entregue a primeira vers\u00e3o completa e revisada do cat\u00e1logo de imagens seguindo a especifica\u00e7\u00e3o STAC . Para isso realizamos uma revis\u00e3o dos metadados utilizando os par\u00e2metros, os requisitos e a especifica\u00e7\u00e3o do Spatial Temporal Asset Catalog (STAC) para o armazenamento das imagens no Banco de dados Geogr\u00e1fico PostGIS; Realizamos alguns testes envolvendo o modelo criado pelo sistema inteligente com algumas imagens do Sentinel-1 e Landsat para o reconhecimento de propriedades de cobertura de terra; Para a visualiza\u00e7\u00e3o dos dados gerados acima tanto para o cat\u00e1logo de imagens quanto para o sistema inteligente, foi realizado uma revis\u00e3o do Web GIS, para se adaptar aos novos par\u00e2metros estabelecidos pela especifica\u00e7\u00e3o do STAC ; Links para as milestones e issues relacionadas \u00e0 quinta entrega (Sprint 5): Sistema Inteligente - testes no modelo criado utilizando a base de dados enriquecida da API; API Resful - entrega da especifica\u00e7\u00e3o da API seguindo os par\u00e2metros do STAC ; Sistema Web GIS - integra\u00e7\u00e3o com a API, implementa\u00e7\u00e3o da busca por dados espa\u00e7o temporais para os par\u00e2metros especificados pelo STAC ; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o de Equipes ATA - Reuni\u00e3o PI ADS Gest\u00e3o de Equipes Gr\u00e1fico de Burndown Gest\u00e3o de Projetos Plano de Risco Gest\u00e3o de Projetos Matriz RACI Sprint 6 (2020 - 07 - 10) \u00b6 Objetivo: Testes com a aplica\u00e7\u00e3o em funcionamento utilizando servidores em nuvem, prioriza\u00e7\u00e3o do funcionamento do sistema inteligente. Valor: Sistema inteligente funcionando com o cat\u00e1logo de imagens STAC com visualiza\u00e7\u00e3o no Web GIS. Descri\u00e7\u00e3o: Entrega do sistema inteligente em funcionamento com a integra\u00e7\u00e3o do cat\u00e1logo de imagens STAC . Em rela\u00e7\u00e3o \u00e0 API de busca, foi implementado o controle de usu\u00e1rios utilizando ferramentas para a abstra\u00e7\u00e3o, em conjunto com o Web GIS (Sistema de visualiza\u00e7\u00e3o) foi implementado o controle e o armazenamento de usu\u00e1rios, foi implementada tamb\u00e9m uma visualiza\u00e7\u00e3o pr\u00e9via das imagens para o download. Atividades Realizadas: Integra\u00e7\u00e3o do sistema inteligente com o cat\u00e1logo de imagens, permitindo que o mesmo possa identificar as propriedades de uso de cobertura de terra minerando os dados necess\u00e1rios; Implementa\u00e7\u00e3o de controle de usu\u00e1rios utilizando o cat\u00e1logo de imagens utilizando um gerenciamento de tokens para cada usu\u00e1rio logado no sistema (usu\u00e1rio administrador e comum); Links para as milestones e issues relacionadas \u00e0 quinta entrega (Sprint 5): Sistema Inteligente - minera\u00e7\u00e3o de dados utilizando a integra\u00e7\u00e3o com o cat\u00e1logo de imagens STAC ; API Resful - implementa\u00e7\u00e3o do controle de usu\u00e1rios por meio de tokens ; Tabela de entregas: Disciplina Entrega de Documentos Empreendedorismo Plano de Neg\u00f3cios Gest\u00e3o de Projetos Canvas Projeto Integrador Contato para D\u00favidas \u00b6 abner.anjos@fatec.sp.gov.br (Abner Ern\u00e2ni dos Anjos) joao.freitas15@fatec.sp.gov.br (Jo\u00e3o de Freitas)","title":"Docs"},{"location":"changes/#sprint-1-2020-03-20","text":"Objetivo: Entregar o ambiente de desenvolvimento para o sistema completo. Valor: Estudo das poss\u00edveis plataformas de desenvolvimento e valida\u00e7\u00e3o de qual a mais adequada. Descri\u00e7\u00e3o: Nesta sprint a prioriza\u00e7\u00e3o foi a defini\u00e7\u00e3o da base de dados para a constru\u00e7\u00e3o da API Restful focando no cat\u00e1logo de imagem e no armazenamento, al\u00e9m da defini\u00e7\u00e3o da interface de usu\u00e1rio para o sistema de visualiza\u00e7\u00e3o Web GIS focando no map tile engine e no recorte e download das imagens. Atividades realizadas: Entrega da defini\u00e7\u00e3o da base de dados a ser utilizada pelo sistema inteligente como cat\u00e1logo de imagens; Adapta\u00e7\u00e3o do Sistema de visualiza\u00e7\u00e3o Web GIS com a configura\u00e7\u00e3o necess\u00e1ria para a visualiza\u00e7\u00e3o dos dados geogr\u00e1ficos; Implementa\u00e7\u00e3o do Open Layers e a estrutura\u00e7\u00e3o do template. Links para as milestones e issues relacionadas \u00e0 primeira entrega (Sprint 1): API Resful - entreg\u00e1vel para a primeira sprint relacionado a API Restful, um interm\u00e9dio para a base de dados constru\u00edda e o sistema Web GIS; Sistema Web GIS - entreg\u00e1vel para a primeira sprint relacionado ao Sistema Web GIS para visualiza\u00e7\u00e3o dos dados de teste; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o de Projetos Termo de Abertura de Projeto Gest\u00e3o de Projetos Diagrama de Tempo e Custo Gest\u00e3o de Projetos Declara\u00e7\u00e3o de escopo Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o Design Thinking Empreendedorismo Canvas","title":"Sprint 1 (2020 - 03 - 20)"},{"location":"changes/#sprint-2-2020-05-15","text":"Objetivo: Montagem do ambiente de desenvolvimento do Sistema Inteligente. Valor: Estudo das poss\u00edveis metodologias para o processamento das imagens. Descri\u00e7\u00e3o: Para esta sprint propomos o desenvolvimento da configura\u00e7\u00e3o inicial do sistema inteligente para a identifica\u00e7\u00e3o de propriedades nas imagens de cobertura de terra capturadas pelo sat\u00e9lite Sentinel e Landsat priorizando a defini\u00e7\u00e3o de m\u00e1scaras. Atividades Realizadas: Entrega da primeira vers\u00e3o do sistema inteligente com a avalia\u00e7\u00e3o dos dados e primeiro processamento de imagens com o cat\u00e1logo de imagens do Sentinel-1; Habilita\u00e7\u00e3o do recorte de pol\u00edgonos no Sistema de visualiza\u00e7\u00e3o; Estrutura\u00e7\u00e3o do projeto completo em micro servi\u00e7os; Documenta\u00e7\u00e3o da instala\u00e7\u00e3o das demais depend\u00eancias como banco de dados PostgreSQL e servidor de mapas Geoserver, criando servi\u00e7os em Docker de forma a facilitar o desenvolvimento. Links para as milestones e issues relacionadas \u00e0 segunda entrega (Sprint 2): Sistema Inteligente - constru\u00e7\u00e3o da base de dados a ser consumida; API Resful - interm\u00e9dio para a base de dados e o sistema Web GIS; Sistema Web GIS - visualiza\u00e7\u00e3o do resultado final; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o BSC - Balanced Scorecard Gest\u00e3o de Projetos Diagrama de Tempo e Custo MS Project Gest\u00e3o de Projetos Vis\u00e3o Geral do Custo de Recursos Gest\u00e3o de Equipes Gr\u00e1fico de Burndown","title":"Sprint 2 (2020 - 05 - 15)"},{"location":"changes/#sprint-3-2020-05-29","text":"Objetivo: Integrar as funcionalidades essenciais da busca por imagens. Valor: Funcionalidade de busca com pol\u00edgonos em GeoJSON. Descri\u00e7\u00e3o: Na sprint 3 com a base de dados definida foi efetuado alguns testes com os modelos do TensorFlow usando um misto de imagens do Sentinel e Landsat para enriquecer os dados de treinamento e valida\u00e7\u00e3o da IA, tamb\u00e9m foi desenvolvida na API Restful uma busca com pol\u00edgonos no banco de dados geogr\u00e1fico e a integra\u00e7\u00e3o com o Web GIS utilizando dados em mock. Atividades Realizadas: Cria\u00e7\u00e3o da base de dados para os os testes envolvendo o modelo criado com o TensorFlow classificador de imagens usando imagens do Sentinel e Landsat; Entrega da API Restful com a busca com pol\u00edgonos formatados em geojson verificando o recorte de imagens feito pelo Sistema Web GIS, verificando se naquele pol\u00edgono existe alguma imagem cadastrada no banco de dados geogr\u00e1fico; Entrega do controle de download do sistema Web GIS para as imagens cadastradas no banco de dados PostGIS, assim como a integra\u00e7\u00e3o com a API Restful e a implementa\u00e7\u00e3o da visualiza\u00e7\u00e3o de camadas no servidor de mapas Geoserver; Links para as milestones e issues relacionadas \u00e0 terceira entrega (Sprint 3): Sistema Inteligente - constru\u00e7\u00e3o do modelo inicial para os testes com uma base de dados m\u00ednima; API Resful - implementando buscas com GeoJSON's para uma API otimizada; Sistema Web GIS - implementando o controle de download para as imagens e a visualiza\u00e7\u00e3o de camadas com o servidor de mapas Geoserver; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o BSC - Balanced Scorecard Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o Planejamento Estrat\u00e9gico em TI Gest\u00e3o de Projetos Matriz RACI Gest\u00e3o de Projetos Checklist Gest\u00e3o de Equipes Gr\u00e1fico de Burndown","title":"Sprint 3 (2020 - 05 - 29)"},{"location":"changes/#sprint-4-2020-06-14","text":"Objetivo: Implementar a pesquisa por dados espa\u00e7o-temporais. Valor: O sistema agora \u00e9 capaz de realizar buscas por imagens com atributos de espa\u00e7o (pol\u00edgonos) e tempo (intervalos de datas). Descri\u00e7\u00e3o: Entrega da API Restful funcionando com dados espa\u00e7o temporais. Para esta sprint foi proposto a cria\u00e7\u00e3o e o treinamento do modelo para a identifica\u00e7\u00e3o de talh\u00f5es assim como a defini\u00e7\u00e3o das m\u00e1scaras para as imagens, a integra\u00e7\u00e3o da API Restful com o sistema de visualiza\u00e7\u00e3o Web GIS para o download e recorte das imagens sem mock, al\u00e9m da implementa\u00e7\u00e3o de tags para os reposit\u00f3rios com controle de vers\u00f5es. Atividades Realizados: Implementa\u00e7\u00e3o do sistema de tags no reposit\u00f3rio do Github, da fun\u00e7\u00e3o de busca por dados espa\u00e7o temporais e enriquecendo a base de dados com mais imagens do Sentinel-1 como teste para o ambiente de produ\u00e7\u00e3o da API; Implementando a busca por dados espa\u00e7o-temporais no Sistema Web GIS com a integra\u00e7\u00e3o com a API utilizando um menu para a abstra\u00e7\u00e3o, habilitando o recorte por pol\u00edgonos e sele\u00e7\u00e3o de intervalos de datas; Visualiza\u00e7\u00e3o dos dados de aprendizagem na \u00e1rea de intelig\u00eancia artificial (acur\u00e1cia) do classificador e testes com o enriquecimento da base de dados da API; Links para as milestones e issues relacionadas \u00e0 quarta entrega (Sprint 4): Sistema Inteligente - visualiza\u00e7\u00e3o de aprendizagem/treino do classificador, aplica\u00e7\u00e3o de t\u00e9cnicas de aumento de dados data augmentation a base de arquivos de teste, enriquecimento da base de dados; API Resful - implementando buscas com intervalos de datas e GeoJSON's, busca por dados espa\u00e7o temporais; Sistema Web GIS - integra\u00e7\u00e3o com a API, implementa\u00e7\u00e3o da busca por dados espa\u00e7o temporais e cria\u00e7\u00e3o do menu para a filtragem das imagens; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o de Projetos ATA - Reuni\u00e3o PI ADS Gest\u00e3o de Projetos Termo de Abertura de Projeto Gest\u00e3o de Projetos Matriz RACI Gest\u00e3o de Projetos Declara\u00e7\u00e3o de Escopo Gest\u00e3o de Projetos Diagrama de Tempo e Custo Gest\u00e3o de Projetos Vis\u00e3o Geral do Custo de Recursos Gest\u00e3o de Projetos Matriz das Comunica\u00e7\u00f5es Gest\u00e3o de Equipes Gr\u00e1fico de Burndown Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o Portf\u00f3lio de Servi\u00e7o ITIL","title":"Sprint 4 (2020 - 06 - 14)"},{"location":"changes/#sprint-5-2020-06-27","text":"Objetivo: Revisar o cat\u00e1logo de imagens com a especifica\u00e7\u00e3o Spatial Temporal Asset Catalog (STAC) . Valor: Cat\u00e1logo de imagens com atributos espa\u00e7o-temporais e a descri\u00e7\u00e3o de cada imagem da base de dados. Descri\u00e7\u00e3o: Entrega da Primeira vers\u00e3o do Cat\u00e1logo de Imagens . Conforme o planejamento desta sprint a prioridade \u00e9 o enriquecimento do cat\u00e1logo de imagens, assim como a base de dados do sistema inteligente e t\u00e9rmino da primeira vers\u00e3o do Web GIS com a integra\u00e7\u00e3o da API Restful. Est\u00e1 no planejamento a reformula\u00e7\u00e3o da API para os par\u00e2metros utilizados pelo Spatial Temporal Asset Catalog (STAC). Atividades Realizadas: Nesta Sprint foi entregue a primeira vers\u00e3o completa e revisada do cat\u00e1logo de imagens seguindo a especifica\u00e7\u00e3o STAC . Para isso realizamos uma revis\u00e3o dos metadados utilizando os par\u00e2metros, os requisitos e a especifica\u00e7\u00e3o do Spatial Temporal Asset Catalog (STAC) para o armazenamento das imagens no Banco de dados Geogr\u00e1fico PostGIS; Realizamos alguns testes envolvendo o modelo criado pelo sistema inteligente com algumas imagens do Sentinel-1 e Landsat para o reconhecimento de propriedades de cobertura de terra; Para a visualiza\u00e7\u00e3o dos dados gerados acima tanto para o cat\u00e1logo de imagens quanto para o sistema inteligente, foi realizado uma revis\u00e3o do Web GIS, para se adaptar aos novos par\u00e2metros estabelecidos pela especifica\u00e7\u00e3o do STAC ; Links para as milestones e issues relacionadas \u00e0 quinta entrega (Sprint 5): Sistema Inteligente - testes no modelo criado utilizando a base de dados enriquecida da API; API Resful - entrega da especifica\u00e7\u00e3o da API seguindo os par\u00e2metros do STAC ; Sistema Web GIS - integra\u00e7\u00e3o com a API, implementa\u00e7\u00e3o da busca por dados espa\u00e7o temporais para os par\u00e2metros especificados pelo STAC ; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o de Equipes ATA - Reuni\u00e3o PI ADS Gest\u00e3o de Equipes Gr\u00e1fico de Burndown Gest\u00e3o de Projetos Plano de Risco Gest\u00e3o de Projetos Matriz RACI","title":"Sprint 5 (2020 - 06 - 27)"},{"location":"changes/#sprint-6-2020-07-10","text":"Objetivo: Testes com a aplica\u00e7\u00e3o em funcionamento utilizando servidores em nuvem, prioriza\u00e7\u00e3o do funcionamento do sistema inteligente. Valor: Sistema inteligente funcionando com o cat\u00e1logo de imagens STAC com visualiza\u00e7\u00e3o no Web GIS. Descri\u00e7\u00e3o: Entrega do sistema inteligente em funcionamento com a integra\u00e7\u00e3o do cat\u00e1logo de imagens STAC . Em rela\u00e7\u00e3o \u00e0 API de busca, foi implementado o controle de usu\u00e1rios utilizando ferramentas para a abstra\u00e7\u00e3o, em conjunto com o Web GIS (Sistema de visualiza\u00e7\u00e3o) foi implementado o controle e o armazenamento de usu\u00e1rios, foi implementada tamb\u00e9m uma visualiza\u00e7\u00e3o pr\u00e9via das imagens para o download. Atividades Realizadas: Integra\u00e7\u00e3o do sistema inteligente com o cat\u00e1logo de imagens, permitindo que o mesmo possa identificar as propriedades de uso de cobertura de terra minerando os dados necess\u00e1rios; Implementa\u00e7\u00e3o de controle de usu\u00e1rios utilizando o cat\u00e1logo de imagens utilizando um gerenciamento de tokens para cada usu\u00e1rio logado no sistema (usu\u00e1rio administrador e comum); Links para as milestones e issues relacionadas \u00e0 quinta entrega (Sprint 5): Sistema Inteligente - minera\u00e7\u00e3o de dados utilizando a integra\u00e7\u00e3o com o cat\u00e1logo de imagens STAC ; API Resful - implementa\u00e7\u00e3o do controle de usu\u00e1rios por meio de tokens ; Tabela de entregas: Disciplina Entrega de Documentos Empreendedorismo Plano de Neg\u00f3cios Gest\u00e3o de Projetos Canvas Projeto Integrador","title":"Sprint 6 (2020 - 07 - 10)"},{"location":"changes/#contato-para-duvidas","text":"abner.anjos@fatec.sp.gov.br (Abner Ern\u00e2ni dos Anjos) joao.freitas15@fatec.sp.gov.br (Jo\u00e3o de Freitas)","title":"Contato para D\u00favidas"},{"location":"python-cnn/","text":"Python Convolutional Neural Networks \u00b6 O sistema deve reconhecer \u00e1reas de talh\u00f5es (unidade m\u00ednima de cultivo de uma propriedade) em um mapa, utilizando dados multitemporais, atrav\u00e9s de intelig\u00eancia artificial, a interface gr\u00e1fica (Web GIS), deve permitir ao usu\u00e1rio selecionar um intervalo de tempo e as imagens de um cat\u00e1logo dispon\u00edvel para a regi\u00e3o selecionada, carregando-as em bloco para n\u00e3o sobrecarregar o sistema e ter op\u00e7\u00e3o para download. Web GIS (Web Geographic Information System): Portal de um \u201cSistema de Informa\u00e7\u00e3o Geogr\u00e1fica\u201d (SIG), baseado em padr\u00e3o de servi\u00e7os web OGC, fornecendo uma estrutura para visualiza\u00e7\u00e3o e navega\u00e7\u00e3o de mapas (basemaps) e de dados geogr\u00e1ficos vetoriais e matriciais. Cat\u00e1logo de Imagem: O Cat\u00e1logo de Imagem deve possibilitar a cataloga\u00e7\u00e3o de cole\u00e7\u00f5es de dados espa\u00e7o-temporal, (metadados) dos sat\u00e9lites Landsat 8 e Sentinel-2. Obs: O cat\u00e1logo de imagem tamb\u00e9m dever\u00e1 fornecer interface (web API) que permitir\u00e1 consultar e recuperar as cenas de sat\u00e9lite catalogadas. Esta interface possibilitar\u00e1 que o Web GIS realize pesquisas complexas, filtrando diferentes par\u00e2metros e especificando crit\u00e9rios geogr\u00e1ficos. Map Tile Engine: Esse componente deve produzir \u201cmap raster tile\u201d para uma determinada cena de sat\u00e9lite, obedecendo ao padr\u00e3o OGC WMTS. Permitindo que usu\u00e1rios do Web GIS visualizem e naveguem pelas imagens sem precisar baix\u00e1-las (real time streaming). Cada map tile \u00e9 uma representa\u00e7\u00e3o visual de parte da imagem, n\u00e3o dos dados em si. Esses tiles geralmente s\u00e3o renderizados em formato pict\u00f3rico (PNG ou JPEG) que podem ser exibidos em uma aplica\u00e7\u00e3o web. Download: Ap\u00f3s a consulta \u00e0s imagens de uma determinada \u00e1rea de interesse, o sistema permite o download de todas as cenas (com todas as suas bandas) do per\u00edodo selecionado pelo usu\u00e1rio (Pilha de imagem). M\u00e1scara (Mask): Neste m\u00f3dulo, o sistema gerar\u00e1 uma m\u00e1scara bin\u00e1ria com as regi\u00f5es de interesse (AOI\u2019s) para cada cena selecionada. A constru\u00e7\u00e3o das m\u00e1scaras de sa\u00edda das \u00e1reas de interesse, se d\u00e3o apresentando valor igual a um (1) dentro desse poligono, enquanto as demais \u00e1reas (\u00e1reas n\u00e3o selecionadas) apresentam valor igual a zero (0). Arquivo: Ap\u00f3s a gera\u00e7\u00e3o da m\u00e1scara para cada cena (scene), \u00e9 preciso armazen\u00e1-la tanto para valida\u00e7\u00e3o visual quanto para download. Com isso, nesse m\u00f3dulo a m\u00e1scara deve ser armazenada de alguma forma que possibilite ao usu\u00e1rio fazer sua valida\u00e7\u00e3o visual (pr\u00f3xima etapa), assim como o download para treinamento de modelos de intelig\u00eancia artificial. Funcionamento das redes neurais convolucionais para o processamento das imagens. Obs.: Instala\u00e7\u00e3o do Miniconda \u00e9 necess\u00e1ria para a execu\u00e7\u00e3o dos comandos a seguir. Ambiente de Desenvolvimento \u00b6 # Montar no ambiente Linux $ sudo apt-get update $ sudo apt-get install python-numpy gdal-bin libgdal-dev # Crie um novo ambiente conda com Python3+ $ conda create --name python-cnn python=3.6.9 # Ativar o ambiente $ conda activate python-cnn # Com o ambiente ativado instalar o ipykernel (python-cnn) $ conda install notebook ipykernel # Com o ipykernel criar um kernel com o python 3.5 autom\u00e1tico (python-cnn) $ ipython kernel install --user --name python-cnn # Instalar o servidor Jupyter Lab (python-cnn) $ python -m pip install jupyter # Instalar a biblioteca gdal e basemap para processar as imagens (python-cnn) $ conda install -c conda-forge gdal=2.4.4 decartes # Executar o servidor em modo de desenvolvimento (python-cnn) $ jupyter notebook Obs.: Pode ser que o Notebook n\u00e3o reconhe\u00e7a o kernel instalado pelo conda, sendo assim voc\u00ea pode alterar manualmente kernel >> Change Kernel >> python-cnn . Ambiente de micro servi\u00e7os em docker \u00b6 # Construir a imagem Docker $ docker build -t jupyter-python-cnn . # Executar a imagem $ docker run --name jupyter-python-cnn-docker -p 8890:8888 -d jupyter-python-cnn C\u00f3digo fonte \u00b6 Tamb\u00e9m ser\u00e1 necess\u00e1rio acesso ao servidores FTP: Sentinel-1 Data ; Sentinel-2 Data ; Landsat-8 Data ; Para a execu\u00e7\u00e3o do c\u00f3digo fonte abaixo \u00e9 necess\u00e1rio o download da pasta data/ , ap\u00f3s o download descompacte na pasta root do projeto. data/ |_ input/ |_ train/ |_ false/ |_ true/ |_ validation/ |_ br_uf/ |_ false/ |_ LEM_shapes/ |_ true/ |_ output/ # !pip install tensorflow numpy matplotlib pillow wget rasterio geopandas xarray keras Importa\u00e7\u00e3o das bibliotecas \u00b6 Importando as bibliotecas necess\u00e1rias para a cria\u00e7\u00e3o do modelo utilizando o tensorflow e o keras . import os import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense , Conv2D , Flatten , Dropout , MaxPooling2D from tensorflow.keras.preprocessing import image from tensorflow.keras.preprocessing.image import ImageDataGenerator import numpy as np import matplotlib.pyplot as plt import matplotlib.image as mpimg # Abstra\u00e7\u00e3o das buscas por pol\u00edgonos e georasters from services.georasters import Georaster from services.vector import Vector Recupera\u00e7\u00e3o de imagens \u00b6 Utilizando a abstra\u00e7\u00e3o criada Georaster para recuperar imagens de sensoriamento remoto do servidor FTP do INPE com o Sentinel-1. Identificando as principais propriedades das imagens e conhecendo os dados antes do pocessamento. data = Georaster ( '2017-06-12 08h:35m:46s' , 'vh' , 4326 ) data . openRemoteFile () data . projection data . downloadRemoteFile () data . convertFileToJPG () data . georaster . read ( 1 ) for coords in data . geom . get ( 'coordinates' ): for coord in coords : print ( data . georaster . read ( 1 )[ int ( coord [ 1 ])][ int ( coord [ 0 ])]) shapes = Vector ( 4326 ) data . geom data_geom = shapes . shape ( data . geom . get ( 'coordinates' )[ 0 ]) data_geom data . geom shapes . lem . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } NM_MUNICIP CD_GEOCMU geometry 0 LU\u00c3\u008dS EDUARDO MAGALH\u00c3\u0083ES 2919553 POLYGON ((-45.71038 -12.39706, -45.71422 -12.3... shapes . covers . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Id area_ha Jun_2017 Jul_2017 Aug_2017 Sep_2017 Oct_2017 Nov_2017 Dec_2017 Jan_2018 Feb_2018 Mar_2018 Apr_2018 May_2018 Jun_2018 Geral variacao var geometry 0 1 341.632515 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxsssxxx xsx s POLYGON ((391870.392 8678209.011, 390327.395 8... 1 523 148.290258 millet millet uncultivated soil uncultivated soil uncultivated soil not identified uncultivated soil not identified not identified uncultivated soil millet millet uncultivated soil llxxx-x--xllx lxlx ll POLYGON ((362953.448 8648254.537, 362492.885 8... 2 3 196.784309 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxsssxxx xsx s POLYGON ((394667.970 8677930.309, 394381.632 8... 3 524 28.625248 sorghum sorghum sorghum uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil zzzxxxxsssxxx zxsx zs POLYGON ((378784.772 8650768.854, 378340.528 8... 4 6 369.452478 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxxssxxx xsx s POLYGON ((398795.097 8680743.662, 398796.144 8... Visualizando os dados \u00b6 Visualizando os dados de entrada para a identifica\u00e7\u00e3o dos talh\u00f5es em uma imagen georreferenciada. shapes . lem . plot ( color = 'black' , edgecolor = 'black' , figsize = ( 8 , 8 )) <matplotlib.axes._subplots.AxesSubplot at 0x7f5f6b4f97b8> shapes . covers . plot ( color = 'white' , edgecolor = 'black' , figsize = ( 8 , 8 )) <matplotlib.axes._subplots.AxesSubplot at 0x7f5eee6a9ef0> Convertendo as imagens \u00b6 Convertendo as imagens em um formato jpg para ser consumido pelo treinamento do modelo. ! ls - l data / input / train / true for i in range ( 11 ): if data . convertAnyFileToJPG ( \"data/input/train/true/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) ! ls - l data / input / train / false for i in range ( 14 ): if data . convertAnyFileToJPG ( \"data/input/train/false/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) ! ls - Rl data / input / train ! ls - l data / input / validation / true for i in range ( 9 ): if data . convertAnyFileToJPG ( \"data/input/validation/true/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) ! ls - l data / input / validation / false for i in range ( 14 ): if data . convertAnyFileToJPG ( \"data/input/validation/false/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) PATH = \"data/input\" Iniciando as vari\u00e1veis para a cria\u00e7\u00e3o do modelo \u00b6 Iniciando as vari\u00e1veis para a identifica\u00e7\u00e3o dos dados de treinamento e valida\u00e7\u00e3o. train_dir = os . path . join ( PATH , 'train' ) validation_dir = os . path . join ( PATH , 'validation' ) train_false_dir = os . path . join ( train_dir , 'false' ) train_true_dir = os . path . join ( train_dir , 'true' ) validation_false_dir = os . path . join ( validation_dir , 'false' ) validation_true_dir = os . path . join ( validation_dir , 'true' ) num_false_tr = len ( os . listdir ( train_false_dir )) num_true_tr = len ( os . listdir ( train_true_dir )) num_false_val = len ( os . listdir ( validation_false_dir )) num_true_val = len ( os . listdir ( validation_true_dir )) total_train = num_false_tr + num_true_tr total_val = num_false_val + num_true_val Entendendo os dados e calculando os items da base de dados. print ( 'total training false images:' , num_false_tr ) print ( 'total training true images:' , num_true_tr ) print ( 'total validation false images:' , num_false_val ) print ( 'total validation true images:' , num_true_val ) print ( \"--\" ) print ( \"Total training images:\" , total_train ) print ( \"Total validation images:\" , total_val ) total training false images: 42 total training true images: 33 total validation false images: 42 total validation true images: 27 -- Total training images: 75 Total validation images: 69 batch_size = 10 epochs = 4 IMG_HEIGHT = 150 IMG_WIDTH = 150 # Generator for our training data train_image_generator = ImageDataGenerator ( rescale = 1. / 255 , horizontal_flip = True , # Inverte a imagem zoom_range = 0.4 , # Aplica zoom rotation_range = 45 , # Rotaciona width_shift_range =. 1 , # Estica horizontalmente a imagem height_shift_range =. 11 , # Estica verticalmente a imagem ) # Vale ressaltar que estas modifica\u00e7\u00f5es nas imagens ocorrem durante as epochs # e ajudam a evitar que o modelo tenha sido treinado com duas imagens iguais # Ent\u00e3o, teoricamente possu\u00edmos mais imagens de teste # Generator for our validation data validation_image_generator = ImageDataGenerator ( rescale = 1. / 255 ) train_data_gen = train_image_generator . flow_from_directory ( batch_size = batch_size , directory = train_dir , shuffle = True , target_size = ( IMG_HEIGHT , IMG_WIDTH ), class_mode = 'binary' ) Found 50 images belonging to 2 classes. val_data_gen = validation_image_generator . flow_from_directory ( batch_size = batch_size , directory = validation_dir , target_size = ( IMG_HEIGHT , IMG_WIDTH ), class_mode = 'binary' ) Found 46 images belonging to 4 classes. sample_training_images , _ = next ( train_data_gen ) # This function will plot images in the form of # a grid with 1 row and 5 columns where images are placed in each column. def plotImages ( images_arr ): fig , axes = plt . subplots ( 1 , 5 , figsize = ( 20 , 20 )) axes = axes . flatten () for img , ax in zip ( images_arr , axes ): ax . imshow ( img ) ax . axis ( 'off' ) plt . tight_layout () plt . show () plotImages ( sample_training_images [: 5 ]) model = Sequential ([ Conv2D ( 16 , 3 , padding = 'same' , activation = 'relu' , input_shape = ( IMG_HEIGHT , IMG_WIDTH , 3 )), MaxPooling2D (), Dropout ( 0.2 ), Conv2D ( 32 , 3 , padding = 'same' , activation = 'relu' ), MaxPooling2D (), Dropout ( 0.1 ), Conv2D ( 64 , 3 , padding = 'same' , activation = 'relu' ), MaxPooling2D (), Dropout ( 0.1 ), Flatten (), Dense ( 512 , activation = 'relu' ), Dense ( 1 ) ]) model . compile ( optimizer = 'adam' , loss = tf . keras . losses . BinaryCrossentropy ( from_logits = True ), metrics = [ 'accuracy' ] ) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 150, 150, 16) 448 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 75, 75, 16) 0 _________________________________________________________________ dropout (Dropout) (None, 75, 75, 16) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 75, 75, 32) 4640 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32) 0 _________________________________________________________________ dropout_1 (Dropout) (None, 37, 37, 32) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 37, 37, 64) 18496 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64) 0 _________________________________________________________________ dropout_2 (Dropout) (None, 18, 18, 64) 0 _________________________________________________________________ flatten (Flatten) (None, 20736) 0 _________________________________________________________________ dense (Dense) (None, 512) 10617344 _________________________________________________________________ dense_1 (Dense) (None, 1) 513 ================================================================= Total params: 10,641,441 Trainable params: 10,641,441 Non-trainable params: 0 _________________________________________________________________ history = model . fit_generator ( train_data_gen , steps_per_epoch = 3 , # total_train epochs = epochs , validation_data = val_data_gen , validation_steps = total_val // batch_size ) WARNING:tensorflow:From <ipython-input-41-2eb3b68c85c4>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version. Instructions for updating: Please use Model.fit, which supports generators. Epoch 1/4 3/3 [==============================] - 247s 82s/step - loss: 1.5138 - accuracy: 0.5333 - val_loss: -2.7784 - val_accuracy: 0.0000e+00 Epoch 2/4 3/3 [==============================] - 292s 97s/step - loss: 2.1543 - accuracy: 0.2000 - val_loss: 0.2031 - val_accuracy: 0.0000e+00 Epoch 3/4 3/3 [==============================] - 149s 50s/step - loss: 0.7297 - accuracy: 0.4667 - val_loss: 0.8846 - val_accuracy: 0.0000e+00 Epoch 4/4 3/3 [==============================] - 161s 54s/step - loss: 0.6469 - accuracy: 0.5000 - val_loss: 1.0150 - val_accuracy: 0.0000e+00 acc = history . history [ 'accuracy' ] val_acc = history . history [ 'val_accuracy' ] loss = history . history [ 'loss' ] val_loss = history . history [ 'val_loss' ] epochs_range = range ( epochs ) plt . figure ( figsize = ( 8 , 8 )) plt . subplot ( 1 , 2 , 1 ) plt . plot ( epochs_range , acc , label = 'Training Accuracy' ) plt . plot ( epochs_range , val_acc , label = 'Validation Accuracy' ) plt . legend ( loc = 'lower right' ) plt . title ( 'Training and Validation Accuracy' ) Text(0.5, 1.0, 'Training and Validation Accuracy') plt . subplot ( 1 , 2 , 2 ) plt . plot ( epochs_range , loss , label = 'Training Loss' ) plt . plot ( epochs_range , val_loss , label = 'Validation Loss' ) plt . legend ( loc = 'upper right' ) plt . title ( 'Training and Validation Loss' ) plt . show () Iniciando os testes com o modelo \u00b6 Testes com o modelo criado anteriormente para a identifica\u00e7\u00e3o de talh\u00f5es. teste = image . load_img ( 'data/input/validation/true/image9.jpg' , target_size = ( IMG_HEIGHT , IMG_WIDTH )) teste = image . img_to_array ( teste ) teste = np . expand_dims ( teste , axis = 0 ) resultado = model . predict ( teste ) plt . imshow ( mpimg . imread ( 'data/input/validation/true/image9.jpg' )) <matplotlib.image.AxesImage at 0x7f5f693a8e10> 'Sim' if resultado [ 0 ][ 0 ] == 1 else 'N\u00e3o' 'N\u00e3o' train_data_gen . class_indices {'false': 0, 'true': 1} lem = rasterio . open ( 'data/input/validation/true/image9.tif' ) shp = gp . read_file ( 'data/output/LEM_2017_2018_mensal_training.shp' ) fig , ax = pyplot . subplots ( figsize = ( 10 , 10 )) rasterio . plot . show ( lem , ax = ax ) shp . plot ( ax = ax , facecolor = \"white\" , edgecolor = \"black\" ) <matplotlib.axes._subplots.AxesSubplot at 0x7f06d7b42ba8> Image Processing Examples \u00b6 Using RasterIO and RasterStats to processing images from STAC service. Install Requirements \u00b6 Import require libraries to image processing ! pip install rasterio rasterstats geopandas numpy To retrieve image metadata, we need the STAC abstraction for STAC Client Python . This is an implementation of the SpatioTemporal Asset Catalog specification for the Brazil Data Cube image and data cube collections ! pip install git + git : // github . com / brazil - data - cube / stac . py @b - 0.8 . 0 #egg=stac Import Requirements \u00b6 import geopandas as gp import rasterio.plot import rasterio import rasterstats import fiona as f import numpy as np from matplotlib import pyplot from pprint import pprint from stac import STAC from rasterstats import zonal_stats , point_query Selecting images \u00b6 First we will select some images from STAC Service using the STAC Client guide for Python users. After create an client for STAC we will retrieve some metadata to understanding the images. stac_client = STAC ( 'http://brazildatacube.dpi.inpe.br/bdc-stac/0.8.0/' ) collection = stac_client . collection ( 'C4_64_16D_MED' ) items = collection . get_items () Downloading the images and saving the local address for later use. red = items . features [ 0 ] . assets [ 'red' ] . download () green = items . features [ 0 ] . assets [ 'green' ] . download () blue = items . features [ 0 ] . assets [ 'blue' ] . download () ndvi = items . features [ 0 ] . assets [ 'ndvi' ] . download () Understanding the image values using rasterio, opening and reading band number 1. rasterio . open ( ndvi ) . read ( 1 ) array([[7821, 7800, 7794, ..., 5711, 6363, 6609], [7817, 7815, 7780, ..., 5665, 6240, 6640], [7876, 7875, 7859, ..., 5845, 6188, 6626], ..., [6053, 5820, 6431, ..., 6565, 6579, 6655], [6725, 6795, 7390, ..., 6296, 6240, 6371], [7061, 7568, 7864, ..., 6240, 6049, 6202]], dtype=int16) ndvi 'C4_64_16D_MED_083100_2019-12-19_2019-12-31_ndvi.tif' r = rasterio . open ( red ) . read ( 1 ) g = rasterio . open ( green ) . read ( 1 ) b = rasterio . open ( blue ) . read ( 1 ) vi = rasterio . open ( ndvi ) r . max () 4369 Opening Images \u00b6 After understanding the images metadata we will open the first image for NDVI and retrieve geometry to later use. def normalize ( array ): \"\"\"Normalizes numpy arrays into scale 0.0 - 1.0\"\"\" array_min , array_max = array . min (), array . max () return (( array - array_min ) / ( array_max - array_min )) rgb = np . dstack (( normalize ( r ), normalize ( g ), normalize ( b ))) pyplot . imshow ( rgb ) <matplotlib.image.AxesImage at 0x7f5ee8214be0> We need to convert the input data to native CRS image. Now using Shapefile. shp = gp . read_file ( 'data/output/LEM_2017_2018_mensal_training.shp' ) shp . crs = vi . crs . to_dict () shp = shp . to_crs ( \"EPSG:4326\" ) Ploting image normalized to see the RGB image. fig , ax = pyplot . subplots ( figsize = ( 15 , 15 )) rasterio . plot . show ( vi , ax = ax ) shp . plot ( ax = ax , facecolor = \"green\" , edgecolor = \"black\" ) <matplotlib.axes._subplots.AxesSubplot at 0x7f5ec063e240>","title":"Sistema Inteligente"},{"location":"python-cnn/#python-convolutional-neural-networks","text":"O sistema deve reconhecer \u00e1reas de talh\u00f5es (unidade m\u00ednima de cultivo de uma propriedade) em um mapa, utilizando dados multitemporais, atrav\u00e9s de intelig\u00eancia artificial, a interface gr\u00e1fica (Web GIS), deve permitir ao usu\u00e1rio selecionar um intervalo de tempo e as imagens de um cat\u00e1logo dispon\u00edvel para a regi\u00e3o selecionada, carregando-as em bloco para n\u00e3o sobrecarregar o sistema e ter op\u00e7\u00e3o para download. Web GIS (Web Geographic Information System): Portal de um \u201cSistema de Informa\u00e7\u00e3o Geogr\u00e1fica\u201d (SIG), baseado em padr\u00e3o de servi\u00e7os web OGC, fornecendo uma estrutura para visualiza\u00e7\u00e3o e navega\u00e7\u00e3o de mapas (basemaps) e de dados geogr\u00e1ficos vetoriais e matriciais. Cat\u00e1logo de Imagem: O Cat\u00e1logo de Imagem deve possibilitar a cataloga\u00e7\u00e3o de cole\u00e7\u00f5es de dados espa\u00e7o-temporal, (metadados) dos sat\u00e9lites Landsat 8 e Sentinel-2. Obs: O cat\u00e1logo de imagem tamb\u00e9m dever\u00e1 fornecer interface (web API) que permitir\u00e1 consultar e recuperar as cenas de sat\u00e9lite catalogadas. Esta interface possibilitar\u00e1 que o Web GIS realize pesquisas complexas, filtrando diferentes par\u00e2metros e especificando crit\u00e9rios geogr\u00e1ficos. Map Tile Engine: Esse componente deve produzir \u201cmap raster tile\u201d para uma determinada cena de sat\u00e9lite, obedecendo ao padr\u00e3o OGC WMTS. Permitindo que usu\u00e1rios do Web GIS visualizem e naveguem pelas imagens sem precisar baix\u00e1-las (real time streaming). Cada map tile \u00e9 uma representa\u00e7\u00e3o visual de parte da imagem, n\u00e3o dos dados em si. Esses tiles geralmente s\u00e3o renderizados em formato pict\u00f3rico (PNG ou JPEG) que podem ser exibidos em uma aplica\u00e7\u00e3o web. Download: Ap\u00f3s a consulta \u00e0s imagens de uma determinada \u00e1rea de interesse, o sistema permite o download de todas as cenas (com todas as suas bandas) do per\u00edodo selecionado pelo usu\u00e1rio (Pilha de imagem). M\u00e1scara (Mask): Neste m\u00f3dulo, o sistema gerar\u00e1 uma m\u00e1scara bin\u00e1ria com as regi\u00f5es de interesse (AOI\u2019s) para cada cena selecionada. A constru\u00e7\u00e3o das m\u00e1scaras de sa\u00edda das \u00e1reas de interesse, se d\u00e3o apresentando valor igual a um (1) dentro desse poligono, enquanto as demais \u00e1reas (\u00e1reas n\u00e3o selecionadas) apresentam valor igual a zero (0). Arquivo: Ap\u00f3s a gera\u00e7\u00e3o da m\u00e1scara para cada cena (scene), \u00e9 preciso armazen\u00e1-la tanto para valida\u00e7\u00e3o visual quanto para download. Com isso, nesse m\u00f3dulo a m\u00e1scara deve ser armazenada de alguma forma que possibilite ao usu\u00e1rio fazer sua valida\u00e7\u00e3o visual (pr\u00f3xima etapa), assim como o download para treinamento de modelos de intelig\u00eancia artificial. Funcionamento das redes neurais convolucionais para o processamento das imagens. Obs.: Instala\u00e7\u00e3o do Miniconda \u00e9 necess\u00e1ria para a execu\u00e7\u00e3o dos comandos a seguir.","title":"Python Convolutional Neural Networks"},{"location":"python-cnn/#ambiente-de-desenvolvimento","text":"# Montar no ambiente Linux $ sudo apt-get update $ sudo apt-get install python-numpy gdal-bin libgdal-dev # Crie um novo ambiente conda com Python3+ $ conda create --name python-cnn python=3.6.9 # Ativar o ambiente $ conda activate python-cnn # Com o ambiente ativado instalar o ipykernel (python-cnn) $ conda install notebook ipykernel # Com o ipykernel criar um kernel com o python 3.5 autom\u00e1tico (python-cnn) $ ipython kernel install --user --name python-cnn # Instalar o servidor Jupyter Lab (python-cnn) $ python -m pip install jupyter # Instalar a biblioteca gdal e basemap para processar as imagens (python-cnn) $ conda install -c conda-forge gdal=2.4.4 decartes # Executar o servidor em modo de desenvolvimento (python-cnn) $ jupyter notebook Obs.: Pode ser que o Notebook n\u00e3o reconhe\u00e7a o kernel instalado pelo conda, sendo assim voc\u00ea pode alterar manualmente kernel >> Change Kernel >> python-cnn .","title":"Ambiente de Desenvolvimento"},{"location":"python-cnn/#ambiente-de-micro-servicos-em-docker","text":"# Construir a imagem Docker $ docker build -t jupyter-python-cnn . # Executar a imagem $ docker run --name jupyter-python-cnn-docker -p 8890:8888 -d jupyter-python-cnn","title":"Ambiente de micro servi\u00e7os em docker"},{"location":"python-cnn/#codigo-fonte","text":"Tamb\u00e9m ser\u00e1 necess\u00e1rio acesso ao servidores FTP: Sentinel-1 Data ; Sentinel-2 Data ; Landsat-8 Data ; Para a execu\u00e7\u00e3o do c\u00f3digo fonte abaixo \u00e9 necess\u00e1rio o download da pasta data/ , ap\u00f3s o download descompacte na pasta root do projeto. data/ |_ input/ |_ train/ |_ false/ |_ true/ |_ validation/ |_ br_uf/ |_ false/ |_ LEM_shapes/ |_ true/ |_ output/ # !pip install tensorflow numpy matplotlib pillow wget rasterio geopandas xarray keras","title":"C\u00f3digo fonte"},{"location":"python-cnn/#importacao-das-bibliotecas","text":"Importando as bibliotecas necess\u00e1rias para a cria\u00e7\u00e3o do modelo utilizando o tensorflow e o keras . import os import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense , Conv2D , Flatten , Dropout , MaxPooling2D from tensorflow.keras.preprocessing import image from tensorflow.keras.preprocessing.image import ImageDataGenerator import numpy as np import matplotlib.pyplot as plt import matplotlib.image as mpimg # Abstra\u00e7\u00e3o das buscas por pol\u00edgonos e georasters from services.georasters import Georaster from services.vector import Vector","title":"Importa\u00e7\u00e3o das bibliotecas"},{"location":"python-cnn/#recuperacao-de-imagens","text":"Utilizando a abstra\u00e7\u00e3o criada Georaster para recuperar imagens de sensoriamento remoto do servidor FTP do INPE com o Sentinel-1. Identificando as principais propriedades das imagens e conhecendo os dados antes do pocessamento. data = Georaster ( '2017-06-12 08h:35m:46s' , 'vh' , 4326 ) data . openRemoteFile () data . projection data . downloadRemoteFile () data . convertFileToJPG () data . georaster . read ( 1 ) for coords in data . geom . get ( 'coordinates' ): for coord in coords : print ( data . georaster . read ( 1 )[ int ( coord [ 1 ])][ int ( coord [ 0 ])]) shapes = Vector ( 4326 ) data . geom data_geom = shapes . shape ( data . geom . get ( 'coordinates' )[ 0 ]) data_geom data . geom shapes . lem . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } NM_MUNICIP CD_GEOCMU geometry 0 LU\u00c3\u008dS EDUARDO MAGALH\u00c3\u0083ES 2919553 POLYGON ((-45.71038 -12.39706, -45.71422 -12.3... shapes . covers . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Id area_ha Jun_2017 Jul_2017 Aug_2017 Sep_2017 Oct_2017 Nov_2017 Dec_2017 Jan_2018 Feb_2018 Mar_2018 Apr_2018 May_2018 Jun_2018 Geral variacao var geometry 0 1 341.632515 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxsssxxx xsx s POLYGON ((391870.392 8678209.011, 390327.395 8... 1 523 148.290258 millet millet uncultivated soil uncultivated soil uncultivated soil not identified uncultivated soil not identified not identified uncultivated soil millet millet uncultivated soil llxxx-x--xllx lxlx ll POLYGON ((362953.448 8648254.537, 362492.885 8... 2 3 196.784309 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxsssxxx xsx s POLYGON ((394667.970 8677930.309, 394381.632 8... 3 524 28.625248 sorghum sorghum sorghum uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil zzzxxxxsssxxx zxsx zs POLYGON ((378784.772 8650768.854, 378340.528 8... 4 6 369.452478 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxxssxxx xsx s POLYGON ((398795.097 8680743.662, 398796.144 8...","title":"Recupera\u00e7\u00e3o de imagens"},{"location":"python-cnn/#visualizando-os-dados","text":"Visualizando os dados de entrada para a identifica\u00e7\u00e3o dos talh\u00f5es em uma imagen georreferenciada. shapes . lem . plot ( color = 'black' , edgecolor = 'black' , figsize = ( 8 , 8 )) <matplotlib.axes._subplots.AxesSubplot at 0x7f5f6b4f97b8> shapes . covers . plot ( color = 'white' , edgecolor = 'black' , figsize = ( 8 , 8 )) <matplotlib.axes._subplots.AxesSubplot at 0x7f5eee6a9ef0>","title":"Visualizando os dados"},{"location":"python-cnn/#convertendo-as-imagens","text":"Convertendo as imagens em um formato jpg para ser consumido pelo treinamento do modelo. ! ls - l data / input / train / true for i in range ( 11 ): if data . convertAnyFileToJPG ( \"data/input/train/true/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) ! ls - l data / input / train / false for i in range ( 14 ): if data . convertAnyFileToJPG ( \"data/input/train/false/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) ! ls - Rl data / input / train ! ls - l data / input / validation / true for i in range ( 9 ): if data . convertAnyFileToJPG ( \"data/input/validation/true/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) ! ls - l data / input / validation / false for i in range ( 14 ): if data . convertAnyFileToJPG ( \"data/input/validation/false/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) PATH = \"data/input\"","title":"Convertendo as imagens"},{"location":"python-cnn/#iniciando-as-variaveis-para-a-criacao-do-modelo","text":"Iniciando as vari\u00e1veis para a identifica\u00e7\u00e3o dos dados de treinamento e valida\u00e7\u00e3o. train_dir = os . path . join ( PATH , 'train' ) validation_dir = os . path . join ( PATH , 'validation' ) train_false_dir = os . path . join ( train_dir , 'false' ) train_true_dir = os . path . join ( train_dir , 'true' ) validation_false_dir = os . path . join ( validation_dir , 'false' ) validation_true_dir = os . path . join ( validation_dir , 'true' ) num_false_tr = len ( os . listdir ( train_false_dir )) num_true_tr = len ( os . listdir ( train_true_dir )) num_false_val = len ( os . listdir ( validation_false_dir )) num_true_val = len ( os . listdir ( validation_true_dir )) total_train = num_false_tr + num_true_tr total_val = num_false_val + num_true_val Entendendo os dados e calculando os items da base de dados. print ( 'total training false images:' , num_false_tr ) print ( 'total training true images:' , num_true_tr ) print ( 'total validation false images:' , num_false_val ) print ( 'total validation true images:' , num_true_val ) print ( \"--\" ) print ( \"Total training images:\" , total_train ) print ( \"Total validation images:\" , total_val ) total training false images: 42 total training true images: 33 total validation false images: 42 total validation true images: 27 -- Total training images: 75 Total validation images: 69 batch_size = 10 epochs = 4 IMG_HEIGHT = 150 IMG_WIDTH = 150 # Generator for our training data train_image_generator = ImageDataGenerator ( rescale = 1. / 255 , horizontal_flip = True , # Inverte a imagem zoom_range = 0.4 , # Aplica zoom rotation_range = 45 , # Rotaciona width_shift_range =. 1 , # Estica horizontalmente a imagem height_shift_range =. 11 , # Estica verticalmente a imagem ) # Vale ressaltar que estas modifica\u00e7\u00f5es nas imagens ocorrem durante as epochs # e ajudam a evitar que o modelo tenha sido treinado com duas imagens iguais # Ent\u00e3o, teoricamente possu\u00edmos mais imagens de teste # Generator for our validation data validation_image_generator = ImageDataGenerator ( rescale = 1. / 255 ) train_data_gen = train_image_generator . flow_from_directory ( batch_size = batch_size , directory = train_dir , shuffle = True , target_size = ( IMG_HEIGHT , IMG_WIDTH ), class_mode = 'binary' ) Found 50 images belonging to 2 classes. val_data_gen = validation_image_generator . flow_from_directory ( batch_size = batch_size , directory = validation_dir , target_size = ( IMG_HEIGHT , IMG_WIDTH ), class_mode = 'binary' ) Found 46 images belonging to 4 classes. sample_training_images , _ = next ( train_data_gen ) # This function will plot images in the form of # a grid with 1 row and 5 columns where images are placed in each column. def plotImages ( images_arr ): fig , axes = plt . subplots ( 1 , 5 , figsize = ( 20 , 20 )) axes = axes . flatten () for img , ax in zip ( images_arr , axes ): ax . imshow ( img ) ax . axis ( 'off' ) plt . tight_layout () plt . show () plotImages ( sample_training_images [: 5 ]) model = Sequential ([ Conv2D ( 16 , 3 , padding = 'same' , activation = 'relu' , input_shape = ( IMG_HEIGHT , IMG_WIDTH , 3 )), MaxPooling2D (), Dropout ( 0.2 ), Conv2D ( 32 , 3 , padding = 'same' , activation = 'relu' ), MaxPooling2D (), Dropout ( 0.1 ), Conv2D ( 64 , 3 , padding = 'same' , activation = 'relu' ), MaxPooling2D (), Dropout ( 0.1 ), Flatten (), Dense ( 512 , activation = 'relu' ), Dense ( 1 ) ]) model . compile ( optimizer = 'adam' , loss = tf . keras . losses . BinaryCrossentropy ( from_logits = True ), metrics = [ 'accuracy' ] ) model . summary () Model: \"sequential\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 150, 150, 16) 448 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 75, 75, 16) 0 _________________________________________________________________ dropout (Dropout) (None, 75, 75, 16) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 75, 75, 32) 4640 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32) 0 _________________________________________________________________ dropout_1 (Dropout) (None, 37, 37, 32) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 37, 37, 64) 18496 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64) 0 _________________________________________________________________ dropout_2 (Dropout) (None, 18, 18, 64) 0 _________________________________________________________________ flatten (Flatten) (None, 20736) 0 _________________________________________________________________ dense (Dense) (None, 512) 10617344 _________________________________________________________________ dense_1 (Dense) (None, 1) 513 ================================================================= Total params: 10,641,441 Trainable params: 10,641,441 Non-trainable params: 0 _________________________________________________________________ history = model . fit_generator ( train_data_gen , steps_per_epoch = 3 , # total_train epochs = epochs , validation_data = val_data_gen , validation_steps = total_val // batch_size ) WARNING:tensorflow:From <ipython-input-41-2eb3b68c85c4>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version. Instructions for updating: Please use Model.fit, which supports generators. Epoch 1/4 3/3 [==============================] - 247s 82s/step - loss: 1.5138 - accuracy: 0.5333 - val_loss: -2.7784 - val_accuracy: 0.0000e+00 Epoch 2/4 3/3 [==============================] - 292s 97s/step - loss: 2.1543 - accuracy: 0.2000 - val_loss: 0.2031 - val_accuracy: 0.0000e+00 Epoch 3/4 3/3 [==============================] - 149s 50s/step - loss: 0.7297 - accuracy: 0.4667 - val_loss: 0.8846 - val_accuracy: 0.0000e+00 Epoch 4/4 3/3 [==============================] - 161s 54s/step - loss: 0.6469 - accuracy: 0.5000 - val_loss: 1.0150 - val_accuracy: 0.0000e+00 acc = history . history [ 'accuracy' ] val_acc = history . history [ 'val_accuracy' ] loss = history . history [ 'loss' ] val_loss = history . history [ 'val_loss' ] epochs_range = range ( epochs ) plt . figure ( figsize = ( 8 , 8 )) plt . subplot ( 1 , 2 , 1 ) plt . plot ( epochs_range , acc , label = 'Training Accuracy' ) plt . plot ( epochs_range , val_acc , label = 'Validation Accuracy' ) plt . legend ( loc = 'lower right' ) plt . title ( 'Training and Validation Accuracy' ) Text(0.5, 1.0, 'Training and Validation Accuracy') plt . subplot ( 1 , 2 , 2 ) plt . plot ( epochs_range , loss , label = 'Training Loss' ) plt . plot ( epochs_range , val_loss , label = 'Validation Loss' ) plt . legend ( loc = 'upper right' ) plt . title ( 'Training and Validation Loss' ) plt . show ()","title":"Iniciando as vari\u00e1veis para a cria\u00e7\u00e3o do modelo"},{"location":"python-cnn/#iniciando-os-testes-com-o-modelo","text":"Testes com o modelo criado anteriormente para a identifica\u00e7\u00e3o de talh\u00f5es. teste = image . load_img ( 'data/input/validation/true/image9.jpg' , target_size = ( IMG_HEIGHT , IMG_WIDTH )) teste = image . img_to_array ( teste ) teste = np . expand_dims ( teste , axis = 0 ) resultado = model . predict ( teste ) plt . imshow ( mpimg . imread ( 'data/input/validation/true/image9.jpg' )) <matplotlib.image.AxesImage at 0x7f5f693a8e10> 'Sim' if resultado [ 0 ][ 0 ] == 1 else 'N\u00e3o' 'N\u00e3o' train_data_gen . class_indices {'false': 0, 'true': 1} lem = rasterio . open ( 'data/input/validation/true/image9.tif' ) shp = gp . read_file ( 'data/output/LEM_2017_2018_mensal_training.shp' ) fig , ax = pyplot . subplots ( figsize = ( 10 , 10 )) rasterio . plot . show ( lem , ax = ax ) shp . plot ( ax = ax , facecolor = \"white\" , edgecolor = \"black\" ) <matplotlib.axes._subplots.AxesSubplot at 0x7f06d7b42ba8>","title":"Iniciando os testes com o modelo"},{"location":"python-cnn/#image-processing-examples","text":"Using RasterIO and RasterStats to processing images from STAC service.","title":"Image Processing Examples"},{"location":"python-cnn/#install-requirements","text":"Import require libraries to image processing ! pip install rasterio rasterstats geopandas numpy To retrieve image metadata, we need the STAC abstraction for STAC Client Python . This is an implementation of the SpatioTemporal Asset Catalog specification for the Brazil Data Cube image and data cube collections ! pip install git + git : // github . com / brazil - data - cube / stac . py @b - 0.8 . 0 #egg=stac","title":"Install Requirements"},{"location":"python-cnn/#import-requirements","text":"import geopandas as gp import rasterio.plot import rasterio import rasterstats import fiona as f import numpy as np from matplotlib import pyplot from pprint import pprint from stac import STAC from rasterstats import zonal_stats , point_query","title":"Import Requirements"},{"location":"python-cnn/#selecting-images","text":"First we will select some images from STAC Service using the STAC Client guide for Python users. After create an client for STAC we will retrieve some metadata to understanding the images. stac_client = STAC ( 'http://brazildatacube.dpi.inpe.br/bdc-stac/0.8.0/' ) collection = stac_client . collection ( 'C4_64_16D_MED' ) items = collection . get_items () Downloading the images and saving the local address for later use. red = items . features [ 0 ] . assets [ 'red' ] . download () green = items . features [ 0 ] . assets [ 'green' ] . download () blue = items . features [ 0 ] . assets [ 'blue' ] . download () ndvi = items . features [ 0 ] . assets [ 'ndvi' ] . download () Understanding the image values using rasterio, opening and reading band number 1. rasterio . open ( ndvi ) . read ( 1 ) array([[7821, 7800, 7794, ..., 5711, 6363, 6609], [7817, 7815, 7780, ..., 5665, 6240, 6640], [7876, 7875, 7859, ..., 5845, 6188, 6626], ..., [6053, 5820, 6431, ..., 6565, 6579, 6655], [6725, 6795, 7390, ..., 6296, 6240, 6371], [7061, 7568, 7864, ..., 6240, 6049, 6202]], dtype=int16) ndvi 'C4_64_16D_MED_083100_2019-12-19_2019-12-31_ndvi.tif' r = rasterio . open ( red ) . read ( 1 ) g = rasterio . open ( green ) . read ( 1 ) b = rasterio . open ( blue ) . read ( 1 ) vi = rasterio . open ( ndvi ) r . max () 4369","title":"Selecting images"},{"location":"python-cnn/#opening-images","text":"After understanding the images metadata we will open the first image for NDVI and retrieve geometry to later use. def normalize ( array ): \"\"\"Normalizes numpy arrays into scale 0.0 - 1.0\"\"\" array_min , array_max = array . min (), array . max () return (( array - array_min ) / ( array_max - array_min )) rgb = np . dstack (( normalize ( r ), normalize ( g ), normalize ( b ))) pyplot . imshow ( rgb ) <matplotlib.image.AxesImage at 0x7f5ee8214be0> We need to convert the input data to native CRS image. Now using Shapefile. shp = gp . read_file ( 'data/output/LEM_2017_2018_mensal_training.shp' ) shp . crs = vi . crs . to_dict () shp = shp . to_crs ( \"EPSG:4326\" ) Ploting image normalized to see the RGB image. fig , ax = pyplot . subplots ( figsize = ( 15 , 15 )) rasterio . plot . show ( vi , ax = ax ) shp . plot ( ax = ax , facecolor = \"green\" , edgecolor = \"black\" ) <matplotlib.axes._subplots.AxesSubplot at 0x7f5ec063e240>","title":"Opening Images"},{"location":"web-gis/","text":"Web GIS \u00b6 Sistema Web GIS para a visualiza\u00e7\u00e3o de talh\u00f5es com dados espa\u00e7o-temporais, permitindo o recorte e buscas de \u00e1reas de interesse por extensivo uso da biblioteca Openlayers . Para a execu\u00e7\u00e3o desta aplica\u00e7\u00e3o ao \u00e9 necess\u00e1rio ter o projeto API Restful em execu\u00e7\u00e3o utilizando Docker ou o ambiente de desenvolvimento. Execu\u00e7\u00e3o para o ambiente de micro servi\u00e7os em Docker \u00b6 Obs.: Necess\u00e1ria instala\u00e7\u00e3o do Node 10+ e Angular CLI 9+ , n\u00e3o esque\u00e7a de modificar o ip do servi\u00e7o de cache em app/services/cache-system.ts . ## Construir o pacote HTML para a execu\u00e7\u00e3o do http-server $ ng build ## Copie o arquivo Dockerfile para o pacote rec\u00e9m-gerado $ cp Dockerfile dist/web-gis && cd dist/web-gis Para a execu\u00e7\u00e3o do ambiente em docker execute os seguintes comandos: ## Crie uma imagem para a execu\u00e7\u00e3o do container $ docker build -t web-gis:latest . ## Fica a criterio do usuario criar um volume para armazenar os dados $ docker container run --name app-smh-ui -p 8082:8080 -d web-gis:latest Abaixo se encontra a aplica\u00e7\u00e3o em funcionamento utilizando os passos anteriores: Este projeto foi gerado utilizando Angular CLI vers\u00e3o 9+. Servidor para o ambiente de desenvolvimento \u00b6 Obs.: N\u00e3o esque\u00e7a de modificar o arquivo de configura\u00e7\u00e3o do proxy para o servidor da API que for utilizar: proxy.conf.js . # Instalar as depend\u00eancias $ npm install # Executar a aplica\u00e7\u00e3o $ npm start Executar o seguinte comando ng serve para executar um novo servidor de desenvolvimento. No navegador procure pelo endere\u00e7o http://localhost:4200/ . A aplica\u00e7\u00e3o ir\u00e1 realizar a leitura autom\u00e1tica de arquivos em conjunto com as altera\u00e7\u00f5es implementadas. Desenvolvimento de c\u00f3digo \u00b6 Executar o seguinte comando ng generate component component-name para gerar um novo componente em Linguagem TypeScript . Gerando pacotes HTML \u00b6 Execute o seguinte comando ng build para gerar o pacote HTML para a execu\u00e7\u00e3o. Use o comando --prod tag para o ambiente de produ\u00e7\u00e3o. Testes Unit\u00e1rios \u00b6 Execute ng test para executar os testes unit\u00e1rios via Karma . Executando testes end-to-end \u00b6 Execute ng e2e para executar o testes end-to-end via Protractor Ajuda FAQ \u00b6 Para maisinforma\u00e7\u00f5es sobre a usabilidade da interface de linha de comando use ng help ou d\u00ea uma olhada Angular CLI README .","title":"Web-GIS"},{"location":"web-gis/#web-gis","text":"Sistema Web GIS para a visualiza\u00e7\u00e3o de talh\u00f5es com dados espa\u00e7o-temporais, permitindo o recorte e buscas de \u00e1reas de interesse por extensivo uso da biblioteca Openlayers . Para a execu\u00e7\u00e3o desta aplica\u00e7\u00e3o ao \u00e9 necess\u00e1rio ter o projeto API Restful em execu\u00e7\u00e3o utilizando Docker ou o ambiente de desenvolvimento.","title":"Web GIS"},{"location":"web-gis/#execucao-para-o-ambiente-de-micro-servicos-em-docker","text":"Obs.: Necess\u00e1ria instala\u00e7\u00e3o do Node 10+ e Angular CLI 9+ , n\u00e3o esque\u00e7a de modificar o ip do servi\u00e7o de cache em app/services/cache-system.ts . ## Construir o pacote HTML para a execu\u00e7\u00e3o do http-server $ ng build ## Copie o arquivo Dockerfile para o pacote rec\u00e9m-gerado $ cp Dockerfile dist/web-gis && cd dist/web-gis Para a execu\u00e7\u00e3o do ambiente em docker execute os seguintes comandos: ## Crie uma imagem para a execu\u00e7\u00e3o do container $ docker build -t web-gis:latest . ## Fica a criterio do usuario criar um volume para armazenar os dados $ docker container run --name app-smh-ui -p 8082:8080 -d web-gis:latest Abaixo se encontra a aplica\u00e7\u00e3o em funcionamento utilizando os passos anteriores: Este projeto foi gerado utilizando Angular CLI vers\u00e3o 9+.","title":"Execu\u00e7\u00e3o para o ambiente de micro servi\u00e7os em Docker"},{"location":"web-gis/#servidor-para-o-ambiente-de-desenvolvimento","text":"Obs.: N\u00e3o esque\u00e7a de modificar o arquivo de configura\u00e7\u00e3o do proxy para o servidor da API que for utilizar: proxy.conf.js . # Instalar as depend\u00eancias $ npm install # Executar a aplica\u00e7\u00e3o $ npm start Executar o seguinte comando ng serve para executar um novo servidor de desenvolvimento. No navegador procure pelo endere\u00e7o http://localhost:4200/ . A aplica\u00e7\u00e3o ir\u00e1 realizar a leitura autom\u00e1tica de arquivos em conjunto com as altera\u00e7\u00f5es implementadas.","title":"Servidor para o ambiente de desenvolvimento"},{"location":"web-gis/#desenvolvimento-de-codigo","text":"Executar o seguinte comando ng generate component component-name para gerar um novo componente em Linguagem TypeScript .","title":"Desenvolvimento de c\u00f3digo"},{"location":"web-gis/#gerando-pacotes-html","text":"Execute o seguinte comando ng build para gerar o pacote HTML para a execu\u00e7\u00e3o. Use o comando --prod tag para o ambiente de produ\u00e7\u00e3o.","title":"Gerando pacotes HTML"},{"location":"web-gis/#testes-unitarios","text":"Execute ng test para executar os testes unit\u00e1rios via Karma .","title":"Testes Unit\u00e1rios"},{"location":"web-gis/#executando-testes-end-to-end","text":"Execute ng e2e para executar o testes end-to-end via Protractor","title":"Executando testes end-to-end"},{"location":"web-gis/#ajuda-faq","text":"Para maisinforma\u00e7\u00f5es sobre a usabilidade da interface de linha de comando use ng help ou d\u00ea uma olhada Angular CLI README .","title":"Ajuda FAQ"}]}